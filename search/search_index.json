{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to 2025 IEEE Summer School and Workshop on Photonics Automation","text":"<p>Overview: This four\u2011day workshop is designed for students and early\u2011career researchers who want to automate photonics experiments. Participants will learn to control optical components, design end\u2011to\u2011end measurement architectures, and convert raw data into clear visualisations. The programm follows the entire automation pipeline\u2014from hardware drivers to data analysis\u2014combining theory with hands\u2011on implementation. While the lectures and demonstrations cover various automation tools, the hands-on sessions will focus primarily on Python.</p> <p>Beyond skills training, the school functions as an interactive forum where students and researchers can present emerging results, debate new methods, and exchange pre\u2011publication ideas. Keynote talks, industry showcases, live lab demonstrations, and structured coding sessions round out an intensive, collaborative learning experience.</p>"},{"location":"#program-structure","title":"Program structure:","text":"<p>Day\u202f1 \u2192 Presentations (peer\u2011reviewed talks)</p> <p>Days\u202f2\u20134 \u2192 Hands-on sessions</p>"},{"location":"#why-enroll","title":"Why Enroll?","text":"<p>Python is rapidly becoming the control language of modern optics labs. In this four\u2011day intensive school you will learn to:</p> <ul> <li> <p>Drive photonic hardware \u2013 integrate lasers, shutters, motorized stages, spectrometers, and cameras through easy\u2011to\u2011read Python scripts.</p> </li> <li> <p>Automate measurements \u2013 create end\u2011to\u2011end workflows that align optics, trigger acquisitions, capture metadata, and stream results in real time.</p> </li> <li> <p>Process &amp; visualize data \u2013 turn raw traces and images into publication\u2011ready insights using NumPy, Pandas, and Matplotlib.</p> </li> <li> <p>Adopt best practices \u2013 version\u2011control experiments, document procedures, and build reusable code modules that scale with your research.   </p> </li> </ul> <p>Target Participants: The symposium welcomes students, early-career researchers, and established scientists, as well as others with a professional interest in experiment automation. Attendees may choose to participate as observers, contribute an oral presentation or poster, or engage in both activities. The hands-on sessions are tailored for undergraduate and graduate students, as well as early-career researchers with a basic knowledge of Python who are looking to apply programming skills to photonics research and experiment automation.</p>"},{"location":"abstracts/","title":"Day 1 Abstracts","text":"<p>Download abstracts (PDF)</p>"},{"location":"abstracts/#keynote-speakers","title":"Keynote speakers","text":""},{"location":"abstracts/#prof-gabriele-grosso-photoluminescence-spectroscopy-automation-for-quantum-optoelectronics","title":"Prof. Gabriele Grosso: Photoluminescence spectroscopy automation for quantum optoelectronics","text":"<p>In this presentation, we highlight recent advancements in controlling the emission of classical and quantum light in low-dimensional materials through advanced experimental techniques. We begin by reviewing key experimental procedures developed in our laboratory and show how automation of photoluminescence spectroscopy enables sophisticated and high-throughput photonic investigations. We then present our latest results from the characterization of artificial atomic structures in two-dimensional (2D) materials. The first part focuses on defect-based quantum emitters in wide bandgap materials and their potential applications in scalable quantum photonic technologies. In the second part, we explore light\u2013matter interactions at phase interfaces in 2D semiconductors, specifically transition metal dichalcogenides (TMDs). Finally, we introduce methods for visualizing dark excitons, revealing their long-range transport enabled by enhanced interactions, and discuss their potential for use in strain sensing applications.</p> <p>Bio: Gabriele Grosso is an Assistant Professor of Physics at the Advanced Science Research Center and the Graduate Center of CUNY. He received his B.S. and M.S. in Physics from the University of Padova. During his master's studies, he was a visiting researcher at the University of California, San Diego. He earned his Ph.D. in Physics from the \u00c9cole Polytechnique F\u00e9d\u00e9rale de Lausanne (EPFL), where he studied polariton quantum fluids. He then joined the Quantum Photonics Group at the Massachusetts Institute of Technology (MIT) as a postdoctoral researcher. Gabriele is a former fellow of the Swiss National Science Foundation and a recipient of the NSF CAREER award. His research focuses on quantum technologies based on light\u2013matter interactions in two-dimensional van der Waals materials and other quantum-confined systems.</p>"},{"location":"abstracts/#prof-haogang-cai-inverse-design-of-meta-optics-using-python","title":"Prof. Haogang Cai: Inverse design of meta-optics using Python","text":"<p>Optical metasurfaces enable abrupt wavefront engineering by locally controlling the light properties (amplitude, phase, etc.). Meta-optics hold great potential to promote a new generation of ultra-compact optical systems. Inverse design strategies have been developed to either improve the optical performance or enable novel functions. In this talk, I will briefly overview the conventional forward design method based on meta-atom library search, and then present two different inverse design examples. Firstly, we demonstrated ultrathin 2D metasurfaces (thickness ~ 1/5 of the wavelength) with nonlocal interactions. We developed a global evolutionary optimization approach based on the genetic algorithm, which improves the resonant metalens focusing efficiency by more than 50%. The optimized designs were experimentally validated based on nanofabrication using electron beam lithography. Secondly, I will also introduce the inverse design of 3D metamaterials with novel multi-functions using the adjoint method. We develop 3D meta-optics to leverage the wealth of invisible wavefront information (e.g., polarization, spatial mode, etc), which are fabricated by two-photon polymerization (TPP) lithography. For both examples, Python is the preferred programing language, taking advantages of available packages for automatic scientific computing and interfacing with FDTD simulation software (Lumerical).</p> <p>Bio: Dr. Haogang Cai is an assistant professor in the Tech4Health Institute and Department of Radiology, at New York University. He has a cross-appointment with the Department of Biomedical Engineering, and is also a member of the Perlmutter Cancer Center, NYU Langone Health. Before joining NYU in 2020, Dr. Cai had postdoctoral trainings at Columbia and Argonne National Laboratory respectively. He received his PhD from the Department of Mechanical Engineering at Columbia University in 2016. Dr. Cai is a receipt of numerous awards, including 2022 Maximizing Investigators' Research Award (MIRA) from National Institute of Health (NIH), 2025 CMBE Rising Stars Award from Biomedical Engineering Society (BMES). His research interests span multidisciplinary topics including biomedical and nanoengineering, optical metasurfaces for bioimaging and biosensing.</p>"},{"location":"abstracts/#prof-euclides-almeida-engineering-nonlinear-metasurfaces-for-light-generation-and-control","title":"Prof. Euclides Almeida: Engineering Nonlinear Metasurfaces for Light Generation and Control","text":"<p>Nonlinear metasurfaces are an emerging class of ultrathin optical elements that enable the generation and control of coherent light through engineered nonlinear optical processes. By leveraging subwavelength structuring, these metasurfaces can facilitate strong light\u2013matter interactions, leading to enhanced harmonic generation, frequency mixing, and other nonlinear effects in compact, planar geometries. Their unique ability to integrate nonlinear generation and wavefront shaping within a single platform opens new avenues for applications in holography, ultrafast optics, nonlinear imaging, and quantum technologies.</p> <p>In this talk, I will present a comprehensive review of nonlinear metasurfaces, with an emphasis on the technical foundations of their design, fabrication, and characterization. I will discuss key design strategies\u2014including material selection, resonant enhancement, and symmetry control\u2014that enable efficient nonlinear responses. The talk will also address challenges in fabrication of nonlinear metasurfaces and measurements of nonlinear signals. Finally, I will explore recent efforts toward automating each stage of the development pipeline, including the use of inverse design, and highlight future directions for reconfigurable nonlinear metasurface technologies.</p> <p>Bio: Euclides Almeida is an Assistant Professor of Physics at Queens College of the City University of New York (CUNY) and a faculty member in the Physics Ph.D. Program at the CUNY Graduate Center. He received his Doctor of Science (D.Sc.) degree in Physics from the Federal University of Pernambuco, Brazil, in 2012, and conducted postdoctoral research at the Weizmann Institute of Science from 2012 to 2017. Prof. Almeida\u2019s research focuses on nanophotonics, nonlinear optics, and metamaterials, with an emphasis on light\u2013matter interactions at the nanoscale. His work aims to develop novel photonic platforms for optical signal processing, coherent light generation, biosensing, and quantum technologies.</p>"},{"location":"abstracts/#prof-eileen-otte","title":"Prof. Eileen Otte","text":"<p>When light interacts with a medium, its spatial structure \u2013 including amplitude, phase, polarization, angular momenta, and more \u2013 is shaped by the medium\u2019s properties across scales, from the macro to the nanoscale. For example, sunlight scattered in the blue daylight sky exhibits intriguing polarization patterns that encode the sun\u2019s position\u2014imperceptible to humans but used by insects like bees for navigation. At much the smaller, molecular level, the emission pattern of a single fluorescent molecule depends on its dipole orientation, allowing nanoscale features to be decoded from the structured light it emits. Inversely, structured light can also be deliberately engineered, making it a powerful tool across a wide range of applications, including optical micro- and nano-manipulation, motion sensing, material machining, and classical as well as quantum communication and encryption. Used in quantum key distribution, structured light increases the dimension, enhancing the information capacity per photon, noise resilience, and transmission distance. We will explore how encoding and decoding information in the structure of light opens new avenues for advancing cutting-edge applications and emerging technologies. </p> <p>Bio  Dr. Eileen Otte joined the Institute of Optics at the University of Rochester as a new faculty member in January 2025. Before, she was a postdoctoral fellow at the Geballe Laboratory for Advanced Materials (GLAM), Stanford University, advised by Prof. Mark Brongersma. Eileen\u2019s research concentrates on the fundamental properties and diverse applications of structured light fields, in areas such as singular optics, nanoscale imaging and sensing, quantum cryptography, optical manipulation, and more. In her postdoctoral research, Eileen focused on nanoscale light-matter interactions, combining structured light and nanophotonics. Eileen performed her PhD work at the University of Muenster, Germany, and University of the Witwatersrand, South Africa; it was honored with summa cum laude as well as the WWU Dissertation Award, and published as a book in the Springer Theses series. She has also received the Research Award 2020 of the Industrial Club Duesseldorf, was appointed a junior class member of the NRW Academy of Sciences, Humanities, and the Arts, and was listed among the Emerging Leaders 2021 and Emerging Talents 2021 of IOP\u2019s Journal of Optics. Her postdoctoral research was supported by the PRIME fellowship of the German Academic Exchange Service as well as Stanford\u2019s GLAM Postdoctoral Fellowship.</p>"},{"location":"abstracts/#prof-samantha-roberts-generative-ai-for-research","title":"Prof. Samantha Roberts: Generative AI for Research","text":"<p>Generative AI tools\u2014especially large language models (LLMs) and emerging multimodal models\u2014are rapidly changing how researchers interact with information. This talk begins with a high-level overview of how these models work, setting realistic expectations for their capabilities and limitations. With that foundation, we\u2019ll explore how generative models can streamline research workflows, from code generation and data analysis to literature review, scientific writing, and knowledge organization. </p> <p>We\u2019ll focus on strategies to make these systems more trustworthy and useful by grounding them in curated, domain-specific content. Retrieval-augmented generation (RAG) and vector-based search are key methods for making this possible, enabling models to reference authoritative sources and deliver more context-aware outputs. Finally, we\u2019ll explore what it means to build \u201cAI-ready\u201d documentation\u2014highlighting how labs and research teams can structure their digital knowledge today to fully leverage AI-enhanced tools in the future.</p> <p>Bio: Samantha Roberts, Ph.D., has served as Director of the ASRC Nanofabrication Facility and Research Assistant Professor since 2022. She earned her Ph.D. in Physics from Cornell University in 2014, conducting research in the Laboratory of Atomic and Solid Physics. Dr. Roberts is an expert in designing and fabricating electrical, photonic, biological, and mechanical nanoscale devices across a range of materials. With two decades of experience in academic shared-user facilities\u2014including Cornell, Columbia, CUNY ASRC, Brookhaven National Lab, Princeton, and UPenn\u2014she brings deep technical knowledge and operational expertise to managing cutting-edge nanofabrication environments. </p> <p>Outside of her formal academic role, Dr. Roberts independently develops applications using pre-trained Generative AI models. She is the creator of nanobot.chat, a domain-specific chatbot for nanofabrication knowledge management. Her focus lies in building GenAI tools that automate tasks and support knowledge workflows in highly specialized domains. She is a strong advocate for using Generative AI to accelerate and enhance research methodologies\u2014not as a replacement for domain expertise, but as a powerful tool to improve efficiency and discovery.</p>"},{"location":"abstracts/#invited-speakers","title":"Invited speakers","text":""},{"location":"abstracts/#dr-matthew-c-strasbourg-practical-python-in-the-lab-high-throughput-optical-spectroscopy-of-quantum-materials","title":"Dr. Matthew C. Strasbourg: Practical Python in the lab: high-throughput optical spectroscopy of quantum materials","text":"<p>Specialized spectroscopies often necessitate custom hardware solutions, creative implementations of instrumentation, real-time data visualization, and traceable analysis of big datasets. While some software packages and programming languages excel at individual aspects of these tasks, Python is uniquely positioned to excel in these applications due to its ubiquity in scientific computing, while also avoiding the overhead associated with other solutions. This talk will cover how automated instrumentation is integrated into optical assemblies and how advanced open-source visualization toolkits and transparent analysis pipelines are utilized to interpret resulting datasets. Additionally, the talk will overview a microscope control platform and data analysis pipeline with specific examples of the complete lifecycle of a custom spectroscopic measurement, including hardware integration, measurement orchestration, data processing, and publication-ready figure rendering. It will highlight instances where automation has directly led to new scientific insights and how this Python-enabled framework supports high-throughput and specialized spectroscopy of quantum materials.</p> <p>Bio: Matt is a Postdoctoral Research Scientist at Columbia University who is developing new measurement techniques that probe emergent many-body effects in 2D materials, imaging materials at the nanometer length scale, and manipulating quantum states of light. He completed his PhD in Physics at Montana State University in 2023, where he utilized low-temperature optical spectroscopy to investigate excited-state thermalization in systems with strong Coulomb interactions and quantum emitter formation in 2D semiconductors. In 2024, he joined the Department of Mechanical Engineering at Columbia, where he now specializes in near-field optical spectroscopy of quantum materials.</p>"},{"location":"abstracts/#dr-deepankur-thureja-disentangling-weakly-coupled-modes-via-global-fitting-of-optical-spectra","title":"Dr. Deepankur Thureja: Disentangling weakly coupled modes via global fitting of optical spectra","text":"<p>Coupled oscillators are a ubiquitous theme in photonics. They provide a unifying language for phenomena involving hybridized modes in diverse platforms, ranging from ultracold atomic gases to semiconductors in optical microcavities. For spectroscopists, this often translates into the routine task of fitting complex spectral features to extract quantitative information from their optical measurements, such as resonance positions, linewidths, and interaction strengths.</p> <p>In this talk, I present a special case encountered in my own research: a Feshbach resonance in a van der Waals heterostructure involving two excitonic modes \u2013 one optically bright, the other entirely dark. In particular, since the coupling strength is much smaller than the intrinsic excitonic linewidth, the interaction is effectively invisible in any single spectrum. Yet, I show how a global fitting strategy overcomes this challenge to reveal the underlying physics.</p> <p>This case study serves as a practical guide for tackling ill-conditioned spectral regression problems. I will walk through a staged fitting pipeline developed in Python: beginning with single-oscillator fits to constrain background parameters, propagating uncertainties across stages, enhancing sensitivity in the anticrossing region via weighted residuals, and ultimately isolating the hidden coupling strength. This approach offers a practical blueprint for extracting quantitative insight from spectroscopic data even when key features remain hidden to the eye.</p> <p>Bio: Deepankur Thureja performed his doctoral research in the Mechanical Engineering and Physics departments at ETH Zurich in the lab of Prof. David Norris and Prof. Atac Imamoglu, where he pioneered electrically tunable quantum confinement of excitons in 2D materials. As a HQI postdoctoral fellow in the group of Prof. Hongkun Park and Prof. Mikhail Lukin at Harvard University, he is exploring strong light-matter interactions in atomically thin semiconductors to advance the development of a solid-state quantum many-body system made of strongly correlated photons.</p>"},{"location":"abstracts/#sarah-jane-baker-automating-data-collection-using-python","title":"Sarah Jane Baker: Automating Data Collection using Python","text":"<p>Coordinating multiple instruments in photonics experiments often requires manual intervention, which can slow data collection and limit reproducibility. In this talk, I will present how I used Python to automate these processes for an experiment I built to measure changes in photoluminescence as a function of applied magnetic field. The Python script I developed controls three instruments simultaneously: a cryostat that sets and stabilizes both the magnetic field and temperature, a mechanical shutter that protects the sample from continuous excitation, and a lock-in amplifier that receives the collected signal. Between each magnetic field setpoint, the script automatically triggers measurements, adjusts experimental conditions, and updates two live plots for real-time visualization. This streamlines long experimental sessions, reduces sample degradation and manual errors, and provides insight into the evolving dataset. The tools and strategies I will share are broadly applicable to many photonics setups that require inter-instrument communication and live data monitoring.</p> <p>Bio: Sarah\u2019s research is at the intersection of nanoscience and photonics. She seeks to develop more efficient photovoltaics to make solar energy harvesting practical to implement on larger scales. Her goal is to use singlet fission macromolecules to drive multielectron photocatalytic reactions. The model frequently used to depict singlet fission discounts the potential for direct harvesting from the coupled biexciton (triplet pair) state\u2014the intermediate state between the singlet and two \u201cfree\u201d triplets\u2014in artificial photosynthetic processes. Sarah aims to optimize energy harvesting by understanding how chromophore design, including descriptions of quantum interference, controls the nature and lifetime of triplet pair states.</p> <p>She will use these concepts to demonstrate how individual triplet excitons can be directly extracted from a triplet pair prior to dissociation, avoiding certain loss-prone processes and ultimately harvesting more energy from less sunlight than current technology allows. Outside of her research, Sarah enjoys drawing, baking, and spending time in the Catskills.</p>"},{"location":"abstracts/#dr-michael-de-oliveira-shaping-light-on-demand-with-a-few-lines-of-code","title":"Dr. Michael de Oliveira: Shaping Light on Demand (with a Few Lines of Code)","text":"<p>Imagine sculpting light\u2014twisting, shaping, and imprinting it with structure\u2014as effortlessly as editing an image on a screen. In today\u2019s photonics labs, this is no longer a fantasy. Spatial light modulators (SLMs) have become versatile, programmable tools that enable real-time control over light\u2019s spatial and temporal properties, driving advances in areas like microscopy, optical tweezing, quantum optics, and beyond. This talk offers an accessible introduction to the principles and practice of shaping light with SLMs. We\u2019ll unpack how these devices work, how phase-only modulation can be used to encode both phase and complex amplitude, and and how to generate a wide range of structured beams\u2014from optical vortices and exotic modes to dynamic space-time beams. We\u2019ll walk through intuitive examples, practical strategies, and common challenges, making this tutorial especially valuable for those new to SLMs or curious about integrating them into automated experimental setups. Whether you\u2019re steering beams, engineering light fields for nonlinear optics, or encoding information for quantum communication, this session will provide a clear and engaging foundation for shaping light in the lab.</p> <p>Bio: Michael de Oliveira spends most of his time convincing light to do increasingly strange and complicated things\u2014twist, spin, heal, or dance through space-time\u2014using devices like spatial light modulators, metasurfaces and a generous dose of stubborn optimism. His research focuses on shaping light across multiple degrees of freedom\u2014phase, polarization, amplitude, frequency, and time\u2014to unlock new effects in photonics, from ultrafast and nonlinear optics to quantum experiments. He firmly believes that light is just misunderstood\u2014and that with enough patience, whispered incantations to Maxwell, and elaborate alignment rituals, it can be made to do almost anything. Probably.</p> <p>Michael joined the ASRC and Prof. Andrea Al\u00f9\u2019s group in 2025 as a Postdoctoral Research Fellow. He earned his PhD in Physics from the Politecnico di Milano in collaboration with the Italian Institute of Technology, where he worked under the supervision of Dr. Antonio Ambrosio on multi-degree-of-freedom control of light for advanced photonic applications. Before that, he completed his BSc in Astronomy &amp; Astrophysics, BSc (Honors), and MSc in Physics with distinction at the University of the Witwatersrand in South Africa, where he began working with structured light under Prof. Andrew Forbes.</p>"},{"location":"abstracts/#dr-pratap-chandra-adak-magnon-mediated-exciton-exciton-interactions-in-a-van-der-waals-antiferromagnet","title":"Dr. Pratap Chandra Adak: Magnon-mediated exciton-exciton interactions in a van der Waals antiferromagnet","text":"<p>CrSBr is a newly discovered material that uniquely combines magnetism with semiconducting properties at the atomic scale. It hosts excitons\u2014bound pairs of electrons and holes\u2014that strongly influence its optical behavior. What makes CrSBr truly remarkable is that these excitons interact with the material\u2019s magnetic state, leading to a new type of coupling between excitons and magnons\u2014the quantum ripples of magnetism. In our recent experiments, we have uncovered how this exciton-magnon interaction enables an indirect interaction between excitons themselves, resulting in strong nonlinear optical effects. This interaction is unusual because excitons and magnons typically do not interact with each other, but in CrSBr, the magnetic environment subtly changes as excitons accumulate, shifting their energy. Our findings deepen our understanding of emergent quasiparticle interactions in quantum materials and point toward promising applications, such as devices that can link microwave and optical signals\u2014useful for next-generation quantum communication.</p> <p>Bio: Dr. Pratap Chandra Adak is a postdoctoral researcher at the City College of New York, working under the guidance of Prof. Vinod Menon. His current research focuses on the interaction of light with two-dimensional (2D) magnetic materials, particularly CrSBr. He has contributed to the discovery of a novel exciton-exciton interaction mediated by magnetic excitations (magnons), enabling strong optical nonlinearities\u2014an advance with potential applications in next-generation photonic and quantum devices. Before this, he earned his Ph.D. from the Tata Institute of Fundamental Research (TIFR) in Mumbai, where he investigated quantum transport in 2D systems such as graphene. His doctoral work revealed a form of the Hall effect that arises not from external magnetic fields, but from the topological structure of flat bands in twisted double bilayer graphene. He is also deeply interested in leveraging Python-based automation for high-throughput experiments and data-driven insights into experimental results.</p>"},{"location":"abstracts/#contributed-speakers","title":"Contributed speakers","text":""},{"location":"abstracts/#sofia-sechi-automation-of-a-mid-infrared-pump-probe-spectroscopy-setup","title":"Sofia Sechi: Automation of a mid-infrared pump-probe spectroscopy setup","text":"<p>Ultrafast pump-probe spectroscopy enables the study of nonequilibrium dynamics in materials on femtosecond timescales. In our setup, mid-infrared pump and probe pulses excite and track phonon resonances in low-symmetry systems. The probe beam is imaged with a mid-IR camera, providing access to both real and momentum (k-) space and allowing investigation of anisotropic dynamics and dispersion phenomena. A motorized delay stage controls the time delay between pulses, while a collinear interferometer analyzes the probe\u2019s spectral components.  LabVIEW software coordinates the entire experiment, synchronizing the camera, translation stage, and interferometer for streamlined data acquisition. This integrated approach enables us to capture both temporal and spectral information, making it possible to visualize ultrafast, direction-dependent processes in complex materials and providing a powerful tool for condensed matter research.</p> <p>Bio: Sofia Sechi earned her Bachelor\u2019s degree in Physics from the University of Cagliari (Sardinia, Italy) in 2024 and is currently pursuing a Master\u2019s degree in Photonics and Nanomaterials at the same institution. She is carrying out her thesis research at the ASRC within Professor Andrea Al\u00f9\u2019s group, working together with postdoctoral researcher Michele Guizzardi. Her work focuses on advanced pump-probe experiments in the mid-infrared range, investigating ultrafast dynamics of phonons in low-symmetry metamaterials.</p>"},{"location":"contact/","title":"Contact","text":"<p>If you have any question or suggestions feel free to contact any organizers below.</p> <p>Organizing Committee</p> <p>Dr. Viktoriia\u202fRutckaia \u2013\u202fGeneral Chair - viktoriia.rutckaia47@gc.cuny.edu</p> <p>Dr. Diana\u202fStrickland \u2013\u202fProgram Chair - dstrickland@gc.cuny.edu</p> <p>Dr. Prachi Thureja \u2013\u202fOperations Chair - pthureja@gc.cuny.edu</p>"},{"location":"flyer/","title":"Flyer","text":""},{"location":"gui/","title":"GUI Tutorial materials","text":"<p>Download materials for GUI tutorial (ZIP)</p>"},{"location":"instructors/","title":"Workshop Instructors","text":""},{"location":"instructors/#dr-mario-marques","title":"Dr. Mario\u202fMarques","text":"<p> Mario Marques is interested in developing density functional theory methods and understanding different light and matter interactions.</p> <p>Previously, Mario Marques investigated how vibrations influence optical properties of photosynthetic bacteria in the group of Prof. Linn Leppert at the University of Bayreuth. He earned his PhD from Martin Luther University of Halle-Wittenberg, where he studied the structure and dynamics of materials using machine learning under the guidance of Prof. Miguel Marques. He completed his undergraduate studies at the University of Coimbra, where he studied optical and magnetical properties of endohedral silicon cages in the group of Prof. Fernando Nogueira.</p>"},{"location":"instructors/#ayisha-yankey","title":"Ayisha Yankey","text":"<p> Hi, my name is Ayisha Yankey. I am currently a high school senior and an incoming Electrical and Computer Engineering major at Carnegie Mellon University. Since last summer, I\u2019ve been working at the ASRC in the photonics lab, where I focus on automating experimental setups. I\u2019m excited to contribute to this workshop and happy to assist in any way I can.</p>"},{"location":"instructors/#dr-romain-tirole","title":"Dr. Romain\u202fTirole","text":"<p> Romain Tirole\u2019s research focuses on the investigation of various materials and nanostructures as platforms for nonlinear optical time-varying media. Time-varying photonics recently surged as a steaming field of research thanks to its promises for control of waves, yet their implementation in optics remains challenging. Using nonlinear optical techniques such as pump-probe spectroscopy, harmonic generation microscopy or Z-scan, Romain explores how the dynamics of charges carriers can help create such devices. With years of hands-on experience synchronizing instruments in tedious measurements, he\u2019s looking forward to sharing his struggles and learned lessons with you! Romain Tirole joined the ASRC and Prof. Andrea Al\u00f9\u2019s team as a Research Fellow in 2023 after receiving his PhD in Physics from Imperial College London working in Prof. Riccardo Sapienza\u2019s group. Previously, Romain completed his undergraduate degrees studying at the University of Cambridge, Imperial College London and the Classe Pr\u00e9paratoire aux Grandes \u00c9coles Pierre de Fermat in Toulouse.</p>"},{"location":"instructors/#dr-evripidis-michail","title":"Dr. Evripidis Michail","text":"<p> Evripidis Michail\u2019s research focuses on light\u2013matter interactions, with the goal of investigating functional optical and electronic properties of materials and nanodevices to enable their integration into advanced technological applications.  His work primarily centers on the design and development of high-throughput, ultrafast optical and optoelectronic probes. These tools enable sensitive spectroscopic characterization of materials and photonic devices under conditions of strong light\u2013matter coupling or intense electromagnetic fields. Through these techniques, he explores distinctive materials' properties, thereby proposing the design of nanodevices or molecular architectures with tailored functionalities, contributing to a robust scientific foundation with relevance to emerging technologies. Evripidis joined the Advanced Science Research Center in 2021 as a Research Associate in Professor Matthew Sfeir\u2019s research group within the Photonics Initiative. He earned his Ph.D. in Applied and Chemical Physics from Julius Maximilians University of W\u00fcrzburg in Germany and received his master\u2019s and bachelor\u2019s degrees in physics from the University of Patras in Greece.</p>"},{"location":"instructors/#kamyar-rashidi","title":"Kamyar\u202fRashidi","text":"<p> I\u2019m an optics and photonics researcher specializing in the optimal design and experimental study of optical and photonic devices. I have hands-on experience testing optical modules, performing various optical measurements (such as spectroscopy and Fourier imaging), and automating these processes using object-oriented programming.\u00a0</p> <p> </p> <p> </p>"},{"location":"instructors/#dr-arash-nemati","title":"Dr. Arash\u202fNemati","text":"<p> Arash Nemati received his Ph.D. in Electrical and Computer Engineering from the National University of Singapore in 2020. He is currently a Postdoctoral Fellow at the Advanced Science Research Center, City University of New York. His research primarily focuses on tunable metasurfaces and optoelectronic devices. He previously served as a Scientist at the Agency for Science, Technology and Research (A*STAR), Singapore. Dr. Nemati has received several recognitions, including the Best Student Paper Award at APNFO12, the Best Poster Award at ICMAT 2019, and the 2018\u20132019 Best Paper Award from Opto-Electronic Advances.</p>"},{"location":"kamyar/","title":"Data Processing Tutorial","text":"<p>Link for Kamyar's tutorial materials:</p> <p>https://github.com/kamyarrashidi034/Analytical-THz-TDS</p>"},{"location":"prerequisites/","title":"Prerequisites \u2014 only for Day 2-4 Hands-On Participants","text":"<p>Day 1 symposium attendees do not need to meet these technical requirements.</p> <ul> <li> <p>Laptop with admin rights and a working install of Python 3.12 (or any current 3.x release). A detailed setup guideline is posted under \"Installation Guideline\" tab.</p> </li> <li> <p>Participants are encouraged to attend a test-run meeting on Monday (time TBA) to ensure the smooth operation of the code during the hands-on sessions. Several back-up computers will be available throughout the workshop in case of troubles with personal laptops.</p> </li> <li> <p>Participants are expected to have a basic knowledge of Python: </p> </li> </ul> Topic You should be able to\u2026 Running Python \u2022 launch the interpreter or Jupyter Notebook\u2022 install a package with <code>pip</code> or <code>conda</code> Variables &amp; data types \u2022 create and print <code>int</code>, <code>float</code>, <code>str</code>, <code>bool</code> values\u2022 understand simple arithmetic and string formatting Collections \u2022 build and index a <code>list</code>, <code>tuple</code>, and <code>dict</code>\u2022 iterate over a list with <code>for item in list:</code> Control flow \u2022 write <code>if / elif / else</code> branches\u2022 use <code>for</code> and <code>while</code> loops, including <code>break</code> / <code>continue</code> Functions \u2022 define a function with <code>def my_func(arg):</code>\u2022 return a value and call the function from another cell Modules \u2022 import a standard library module (<code>import math</code>, <code>import time</code>) Basic I/O \u2022 read / write a text file with <code>open()</code> Very light OOP awareness \u2022 know that a class bundles data and methods\u2014even if you\u2019ve never written one (we\u2019ll start there on Day 2) <p>We recommend these online courses if you would like to refresh your knowledge:</p> <p>https://programming-22.mooc.fi/</p> <p>https://cs50.harvard.edu/python/2022/</p>"},{"location":"program_day1/","title":"Day 1 Symposium","text":"<p>Download Agenda (PDF)</p> <p>Download full program (PDF)</p> <p>Date: July 7, 2025 Location: CUNY ASRC Auditorium</p> Time &amp; Type Speaker &amp; Affiliation Title 09:00\u201309:10 Viktoriia Rutckaia Introductory Comments 09:10\u201309:40Keynote 1 Gabriele GrossoASRC CUNY Photoluminescence spectroscopy automation for quantum optoelectronics 09:40\u201310:00Invited 1 Matthew C. StrasbourgColumbia University Practical Python in the lab: high-throughput optical spectroscopy of quantum materials 10:00\u201310:20Invited 2 Deepankur ThurejaHarvard University Disentangling weakly coupled modes via global fitting of optical spectra Coffee Break \u2014 10:20\u201310:40 10:40\u201311:10Keynote 2 Haogang CaiNYU Inverse design of meta-optics using Python 11:10\u201311:40Keynote 3 Euclides AlmeidaQueens College CUNY Engineering nonlinear metasurfaces for light generation and control 11:40\u201312:00Invited 3 Sarah Jane BakerASRC CUNY Automating data collection using Python Lunch Break, Lab Tours \u2014 12:00\u201313:30 13:30\u201314:00Keynote 4 Eileen OtteUniversity of Rochester Beyond the Beam: The Potential of Light\u2019s Structure 14:00\u201314:20Invited 4 Michael de OliveiraASRC CUNY Shaping Light on Demand (with a Few Lines of Code) 14:20\u201314:50Keynote 5 Samantha RobertsASRC CUNY Generative AI for research 14:50\u201315:10Invited 5 Pratap Chandra AdakCCNY CUNY Magnon-mediated exciton-exciton interactions in a van der Waals antiferromagnet Coffee Break \u2014 15:10\u201315:30 15:30\u201315:45Contributed talk Sofia SechiUniversity of Cagliari Automation of a mid-infrared pump-probe spectroscopy setup 15:45\u201316:15Industry Session James Scholz, Joseph DemarestVyir Tech Automating optical setups for efficiency and accuracy 16:15\u201316:20 Viktoriia Rutckaia Closing Remarks 16:20\u201317:00 Mario Marques, Ayisha Yankey Laptop check for participants joining hands-on sessions (July 8-10)"},{"location":"program_days2-4/","title":"Days 2-4 Hands-on Sessions","text":""},{"location":"program_days2-4/#tuesday-8-july-2025","title":"Tuesday, 8 July 2025","text":"<p>9:00am \u2013 9:30am Welcome words and Introduction Viktoriia Rutckaia and Diana Strickland</p> <p>9:30am \u2013 12:30pm Morning session 1:  Controlling optical elements with Python INSTRUCTOR: DR. MARIO MARQUES</p> <p>The morning begins with a concise introduction to object-oriented Python\u2014showing how to package commands and data into clean, reusable \u201cobjects.\u201d Participants practice by turning a short procedural script into a self-contained class, creating a generic template for hardware control and adapting it to different devices, then wrapping settings and results into an experiment object that can scan a variable, plot the outcome, and save everything to a file. By lunchtime everyone will have run a simple automated measurement and stored the data.</p> <p>12:30pm \u2013 2:00pm Lunch, tours, project distribution</p> <p>2:00pm \u2013 3:00pm Afternoon session 1: Setting up your GitHub repository; Reviewing libraries and classes  INSTRUCTOR: AYISHA YANKEY</p> <p>3:00pm \u2013 5:00pm Independent study and working on the projects.</p>"},{"location":"program_days2-4/#wednesday-9-july-2025","title":"Wednesday, 9 July 2025","text":"<p>9:00am \u2013 12:30am Morning Session 2: Graphical user interface and coding architecture INSTRUCTOR: DR. ROMAIN TIROLE</p> <p>Building on the morning\u2019s classes, the afternoon shifts to user interfaces. After a quick tour of PyQt Designer, attendees create a widget for their motorized stage, then wire it to the underlying Stage class using Model-View-Controller principles. Next, they add real-time plotting by connecting signals and slots to a power-meter class, yielding a live-acquisition dashboard.</p> <p>12:30pm \u2013 1:30pm Lunch</p> <p>1:30pm \u2013 3:00pm Afternoon session 2: Introduction in LabVIEW, Z-scan demo INSTRUCTOR: DR. EVROS MICHAIL</p> <p>In this hands-on demonstration, a simple LabVIEW example is showcased that implements real-time code to control a translating moving stage along a focused laser beam. A thin film sample is placed on the stage, which moves precisely while simultaneously measuring the optical transmission through a photodiode positioned after the sample. The code will be written from scratch live, with opportunities for participants to modify parameters themselves, fostering an interactive learning experience. This setup provides a quick demonstration inspired by the principles of a Z-scan optical measurement system, where transmission is measured at different incident energy fluences.</p> <p>3:00pm \u2013 5:00pm Independent study and working on the projects.</p>"},{"location":"program_days2-4/#thursday-10-july-2025","title":"Thursday, 10 July 2025","text":"<p>9:00am \u2013 12:30pm Morning session 3:  Python Control for ultrafast lasers, Data Visualization with Python INSTRUCTOR: KAMYAR RASHIDI</p> <p>In this session I will discuss how to control hardware for ultrafast spectroscopy using Python. We will learn how to interface and control various components in an optical setup, such as the laser, delay stage, optical rotation components, as well as the sampling and detection systems. Additionally, we will review methods for data collection and analysis, providing a comprehensive understanding of how to manage both the hardware and the data throughout the spectroscopy process.</p> <p>12:30pm \u2013 2:00pm Lunch, project presentations, group picture.</p> <p>2:00pm \u2013 4:30pm Afternoon session 3: Python control &amp; data acquisition with the Rigol DP832 INSTRUCTOR: DR. ARASH NEMATI</p> <p>In this hands-on session we will explore how to automate laboratory hardware using Python and the PyVISA library, featuring the Rigol DP832 programmable power supply as our primary example. We will walk through each step of connecting to and querying the device, configuring voltage/current setpoints, and performing controlled sweeps to characterize system behavior (e.g., voltage or current sweeps). By running live demonstrations of Python scripts, participants will observe how to capture real-time data\u2014such as measured voltages and currents\u2014and generate plots for analysis and reporting. We will also discuss important safety and equipment-protection measures, including setting appropriate voltage/current limits, managing output channels, and verifying signal integrity. By the end of this workshop, attendees will have practical experience in Python-based instrumentation control, data visualization (Matplotlib), and essential troubleshooting strategies for research settings.</p> <p>4:30pm \u2013 5:00pm Concluding remarks</p>"},{"location":"projects/","title":"Team projects","text":"<p>Download project descriptions (PDF)</p>"},{"location":"registration/","title":"How to Join:","text":""},{"location":"registration/#day-1-symposium-open-to-all","title":"Day\u202f1 Symposium (open to all)","text":"<p>Free registration here. Specify whether you would like to participate only in Day 1 Symposium or also in the Days 2-4 Hands-On Sessions. </p> <p>Optional abstract (limit to 1 page including figures) for a peer\u2011reviewed 15\u2011min talk or poster; acceptance decisions emailed in June. Send your abstracts to viktoriia.rutckaia47@gc.cuny.edu.</p>"},{"location":"registration/#days-2-4-handson-sessions-limited-seats","title":"Days 2-4 Hands\u2011On Sessions (limited seats)","text":"<p>Prepare a motivation statement (up to one page) with your registration. Send it to viktoriia.rutckaia47@gc.cuny.edu.</p> <p>Seats awarded by the committee; submitting a Day\u202f1 abstract boosts your chances.</p> <p>Apply by 15\u202f June \u202f2025; acceptance results within two weeks.</p>"},{"location":"support/","title":"Support the Workshop and Future STEM Outreach","text":"<p> Your contribution\u2014whether a corporate sponsorship, foundation grant, or personal donation\u2014helps us run a high-impact event and seed future programs that prepare students and early-career researchers for success in photonics and wider STEM fields.</p> <p>Partnering with the 2025 IEEE Summer School and Workshop on Photonics Automation puts your brand in front of the next generation of optics innovators. Depending on the support level, sponsors may receive:</p> <ul> <li> <p>Brand visibility \u2013 logo on the workshop website, program booklet, and podium slides throughout the workshop.</p> </li> <li> <p>Spotlight talk \u2013 a 5-minute vendor/industry flash talk or live demo during the Industry Showcase.</p> </li> <li> <p>Exhibit table \u2013 space for hardware displays, brochures, and one-on-one conversations with attendees.</p> </li> <li> <p>Acknowledgement on the workshop website (the site will stay online as a repository of slides, code, and other materials for future events)</p> </li> </ul> <p>Have another idea\u2014equipment loans, swag, snacks, or student award? We\u2019re flexible and happy to tailor a package that aligns with your mission.</p> <p>Interested in partnering or donating? Email Dr. Viktoriia Rutckaia at viktoriia.rutckaia47@gc.cuny.edu to discuss how your support can make a lasting impact on this workshop and the next generation of STEM talent.</p>"},{"location":"venue/","title":"Venue","text":"<p>Advanced Science Research Center, CUNY</p> <p>85 St. Nicholas Terrace</p> <p>New York, NY 10031 USA</p> <p>For directions and building access, see the ASRC\u2019s Visitor Information page. </p> <p></p>"},{"location":"python/classes/","title":"Overview of classes","text":""},{"location":"python/classes/#introduction-to-classes","title":"Introduction to classes","text":"<p>Python is an object-oriented programming language. A class in Python serves as a blueprint for creating objects, which are instances of the class. (Image on the left was created with chatGPT.)</p> <p>Classes enable you to encapsulate data (class attributes) and behaviors (class methods) in a single entity, which make your code modular and easier to manage. Classes allow you to reuse code and avoid repetition, abstract away the implementation details of concepts and objects, and make your code more flexible and adaptable. By building a similar interface in different classes, you can then use each class interchangeably, for example: you might have a class to calculate energy of solids, molecules, or atoms and use such interface to build different calculators, i.e. objects that will use different codes to calculate the energy, such as Octopus for DFT, or Tensorff for a force-field. An example is the ASE module for python. </p> <p>Another example is feeding an animal. Imagine you have a dog, and you want to feed it, you need to get a certain amount of dog food and put it in is bowl. What if you have a cat instead? It will be different. Still you can make the action of feeding the animal and then do it differently for each animal. In object-oriented programming, you can have this action of feeding the animal as an interface, and then use the feed the cat or dog method as necessary. </p> <p>There is a certain hierarchy to programming involving stages of abstraction. Simpler programs, are just top-down scripts. The next level of abstraction takes us to function-driven applications. Creating objects involves a further stage of abstraction. Object orientation can help to reduce complexity, particularly in long programs. </p>"},{"location":"python/classes/#class-definition","title":"Class definition","text":"<p>You define classes in Python using the class keyword, and instantiate them to create objects, like this</p> <pre><code>class Dog():\n    ...\n\nmy_dog = Dog()\n</code></pre> <p>Note: In Python, ... (three dots) is called Ellipsis, a built-in object used as a placeholder. It\u2019s useful when code isn\u2019t complete yet, offering a cleaner alternative to pass. Read more here</p> <p>Inside the class, you have the body of the class, where you can define the attributes and the methods of the class. It has its own namespace and to access those attributes and methods you need to go through the class or its objects. Let us improve our dog class:</p> <pre><code>import numpy as np\n\nclass Dog:\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n</code></pre> <p>Often, it is easier to understand a concept when you make analogies. So, think yourself of a dog breeder that wants to start breeding dogs. What is a dog? For now, a dog is something that can walk and bark with a characteristic sound, has a name, age, and a color. It also exists somewhere. In other words, our dog class has 5 attributes (name, age, color, position, sound) and 2 methods (walk, bark).</p> <p>Actually, our dog class has one more method: the __init__. The __init__ method has a special meaning in Python classes. This method is known as the object initializer because it defines and sets the initial values for the object\u2019s attributes. </p> <p>You may have notice that the first argument of the methods was always self. It is a convention in python to use self to hold the reference to the current instance (of the object), which allows you to access that instance from within methods.</p> <pre><code>import numpy as np\n\nclass Dog:\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n    def get_name(self):\n        return self.name\n\nmy_dog  = Dog(\"Gandalf\", 3)\nother_dog = Dog(\"Bluey\", 3)\n\nprint(my_dog.get_name())\nprint(other_dog.name)\n</code></pre> <p>The output will be</p> <p><pre><code>Gandalf\nBluey\n</code></pre> With every instantiation, you create a new object of the target class. You can access the attributes and methods of an object by using dot notation with the dot operator. You can also easily change the attributes of the instance of the class:</p> <p><pre><code>other_dog.name = \"Bingo\"\nprint(other_dog.name)\n</code></pre> will output</p> <pre><code>Bingo\n</code></pre> <p>Note about naming conventions: usually, python programmers use snake_case for names of methods and functions. While class names usually use PascalCase, where each word is capitalized. You can read more about it here</p>"},{"location":"python/classes/#how-to-get-more-information-on-the-contents-of-a-class","title":"How to get more information on the contents of a class?","text":"<p>First, you can try to use special python functions. Such as</p> <ul> <li> <p>locals: function returns a dictionary representing the current local symbol table.</p> </li> <li> <p>vars: function returns the dictionary attribute of an object.</p> </li> <li> <p>dir: function returns all properties and methods of the specified object, without the values.</p> </li> </ul> <p>Each class or instance also possess a special dictionary __dict__: this attribute holds a dictionary containing the writable members of the underlying class or instance.</p> <p>Here is an example, try it yourself</p> <pre><code>print(\"\\nlocals: \", locals())\nprint(\"\\ndir Dog: \", dir(Dog))\nprint(\"\\ndir my_dog: \", dir(my_dog))\nprint(\"\\nvars: \", vars(my_dog))\nprint(my_dog.__dict__)\n</code></pre> <p>Alternatively, check the source. You can always check the content of a class if you search for the .py file where it is written. Here is the one we have been writing. </p> <pre><code>import numpy as np\n\nclass Dog:\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nmy_dog  = Dog(\"Gandalf\", 3)\n\n\nprint(\"\\nlocals: \", locals())\nprint(\"\\ndir Dog: \", dir(Dog))\nprint(\"\\ndir my_dog: \", dir(my_dog))\nprint(\"\\nvars: \", vars(my_dog))\nprint(my_dog.__dict__)\n</code></pre> <p>If you want to check a file from a package that you installed, you need to look for the site-packages folder on your environment. For example, numpy installed in an environment env in ubuntu is in</p> <pre><code>env/lib/python3.13/site-packages/numpy\n</code></pre>"},{"location":"python/classes/#public-and-private-attributes-and-methods","title":"Public and private attributes and methods","text":"<p>In python, you do not really have public, private, or protected attributes or methods. However, there is a convention: non_public attributes or methods are named with leading underscores, and these should not be used outside the class. Nothing stops you from doing it, but it is considered bad practice.</p> <p>Two underscores preceding the name of an attribute or method will trigger name mangling though. Python adds the name of the class preceded by an underscore to it. Here is an example:</p> <p><pre><code>class Dog:\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n        self.__favorite_food = \"chicken\"\n</code></pre> If you now try to print __favorite_food: </p> <pre><code>my_dog  = Dog(\"Gandalf\", 3)\nprint(my_dog.__favorite_food)\n</code></pre> <p>you get an error: <pre><code>    print(my_dog.__favorite_food)\n          ^^^^^^^^^^^^^^^^^^^^^^^\nAttributeError: 'Dog' object has no attribute '__favorite_food'. Did you mean: '_Dog__favorite_food'?\n</code></pre></p>"},{"location":"python/classes/#different-types-of-class-attributes","title":"Different types of class attributes","text":"<p>There are different types of attributes:</p> <ul> <li> <p>Class attributes: variables that you define inside the body of the class. Their data is common to the class and all its instances.</p> </li> <li> <p>Instance attributes: Variables that you define inside an instance method (methods that have self as first argument). Their data is only available to the current instance and defines its state. Usually they should be defined in __init__.</p> </li> </ul> <p><pre><code>import numpy as np\n\nclass Dog:\n    # class attributes\n    owner_name = \"Mario\"\n    number_dogs = 0\n\n    def __init__(self, name, age):\n        # instance attributes\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n</code></pre> Note: If you want to keep track of the number of times your class was used, i.e. keep track of the number of dogs created, you can do something like this:</p> <pre><code>import numpy as np\n\nclass Dog:\n    owner_name = \"Mario\"\n    number_dogs = 0\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n        type(self).number_dogs += 1\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nmy_dog = Dog(\"Gandalf\", 3)\nDog(\"Rada\",1)\nDog(\"Vada\",3)\nDog(\"Wada\",2)\nprint(Dog.number_dogs)\n</code></pre> <p>Which will print</p> <p><pre><code>4\n</code></pre> What if we want to add attributes to a class or instance dynamically? We can use setattr for that. setattr: function in Python that is used to set the value of an attribute of an object. It takes three arguments: the object, the name of the attribute (as a string), and the value to set. <pre><code>class Dog:    \n    \"\"\" attributes to be added \"\"\"\n\ninfo_my_dog = {\"name\": \"Gandalf\",\n                \"age\": 3,\n                \"color\":\"white\"\n                }\n\nmy_dog = Dog()\n\nfor key, val in info_my_dog.items():\n    setattr(my_dog, key, val)\n    # setattr(Dog, key, val)\n\nprint(my_dog.name)\n</code></pre></p>"},{"location":"python/classes/#different-types-of-class-methods","title":"Different types of class methods","text":"<p>You can have three different kinds of methods: Instance methods, class methods, and static methods. Let us take a closer look at them:</p> <ul> <li>Instance methods: Methods to be used by the current instance, these take self as first argument. Instance methods should act on instance attributes by either accessing them or changing their values.</li> </ul> <p>Examples are the methods (walk, bark) shown above.</p> <ul> <li>Class methods: methods to be used by the class, these take cls (another strong convention in Python) as first argument.</li> </ul> <p>As an example, we can make another constructor for the class, (the current constructor is used when we call Dog() and takes the same arguments as the __init__):</p> <p><pre><code>import numpy as np\n\nclass Dog:\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n    @classmethod\n    def make_dog(cls, sequence):\n        return cls(*sequence)\n\n\n# my_dog  = Dog(\"Gandalf\", 3)\n\nmy_dog = Dog.make_dog([\"Gandalf\", 3])\nprint(my_dog.name)\n</code></pre> Here we used the decorator @classmethod. We can find more about decorators here python-pep, gfg-decorators. Decorators are a powerful and flexible way to modify or extend the behavior of functions or methods, without changing their actual code. A decorator is essentially a function that takes another function as an argument and returns a new function with enhanced functionality. </p> <p>We can also use class methods to change class attributes like owner_name:</p> <pre><code>import numpy as np\n\nclass Dog:\n    owner_name = \"Mario\"\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n    @classmethod\n    def make_dog(cls, sequence):\n        return cls(*sequence)\n\n    @classmethod\n    def change_owner(cls, name):\n        cls.owner_name = name\n\n# my_dog  = Dog(\"Gandalf\", 3)\n\nmy_dog = Dog.make_dog([\"Gandalf\", 3])\nprint(my_dog.owner_name)\nmy_dog.change_owner(\"Vika\")\nprint(my_dog.owner_name)\n</code></pre> <ul> <li>Static methods: general methods that do not take the current instance or the class. They are included in the body of the class however because they provide important or useful functionality.</li> </ul> <p>Here is an example:</p> <pre><code>import numpy as np\n\nclass Dog:\n    owner_name = \"Mario\"\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n    @classmethod\n    def make_dog(cls, sequence):\n        return cls(*sequence)\n\n    @classmethod\n    def change_owner(cls, name):\n        cls.owner_name = name\n\n    @staticmethod\n    def get_info(name):\n        print(\"Hello {}! This class creates a Dog object that can walk and bark.\"\n              .format(name))\n\nmy_dog = Dog.get_name([\"Gandalf\", 3])\nmy_dog.get_info(\"Mario\")\n</code></pre>"},{"location":"python/classes/#special-methods","title":"Special Methods","text":"<p>Python also has special methods (also known as dunder or magic methods) that have names starting and ending with double underscores, like __init__. These are typically instance methods, and they are essential for python. They are called automatically in response to certain operations.</p> <p>There are many special methods, some examples are:</p> <ul> <li>__str__ : informal string representation, i.e., returns a string that must represent the object. Can be access with str() or print() </li> <li>__repr__ :  formal string representation, i.e., returns a string that should contain all the information to recreate the object.</li> <li>__add__ : It defines the behavior of the addition operator + for objects of a class. Can be very useful, for example when creating a matrix class.</li> </ul> <p>You can get more information about these methods here gfg-dunder, pm-dunder</p>"},{"location":"python/classes/#how-to-reuse-code-and-make-relationships-between-classes","title":"How to reuse code and make relationships between classes?","text":"<p>Sometimes you want to expand a class, or change a method, or even a few methods from a previous written class. Or you want to organize your code and make it more modular. In object-oriented programming there are several design techniques you can use to do that. Here, we will briefly discuss the major two: inheritance and composition. There are others though, such us dependency injection and delegation.</p> <p>Following our breeder analogy, now we want to specialize in certain dog breeds. We want our dogs to have characteristics of certain breeds.</p>"},{"location":"python/classes/#inheritance","title":"Inheritance","text":"<p>This design technique, consists of creating hierarchical relationships between classes, where child classes inherit attributes and methods from their parent class. Our dog class will be the child class, and we will use a certain breed of dogs as a parent class.</p> <p>Let us start by creating a new parent class called Samoyed. Samoyed is a breed of dogs known for two things, working, by pulling sledges, and looking cute.</p> <pre><code>import numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass Samoyed:\n    def __init__(self):\n        self.color = \"white\"\n        self.position = np.zeros(4)\n\n    def work(self):\n        print(\"Pulling a sledge\")\n        self.position += np.random.randint(0,5,4) + np.array([0,0,0,1])  \n\n    def look_cute(self):\n        img = Image.open(\"gandalf1.jpg\")\n        img = np.asarray(img)\n        plt.imshow(img)\n        plt.show()\n</code></pre> <p>Note: if you found the word sledge to be badly placed, you can read about dogsleds here.</p> <p>Now, we will give this functionality to our dog class, i.e., we are going to start creating Samoyeds.</p> <p><pre><code>class Dog(Samoyed):\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.sound = \"Waf waf\"\n        self.color = \"black\"\n        self.position = np.zeros(4)\n        super().__init__()\n        #Samoyed.__init__(self)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nmy_dog = Dog(\"Gandalf\", 3)\n\nmy_dog.work()\nprint(my_dog.position)\nmy_dog.walk()\nprint(my_dog.position)\n</code></pre> The output of this program can be (note that the values are random):</p> <pre><code>Pulling a sledge\n[3. 4. 2. 5.]\nWalking on four legs\n[3. 5. 3. 6.]\n</code></pre> <p>The super() function above allows you to access members in the superclass or parent class. We could have used Samoyed() instead, as shown in the comment. Our Dog class inherited the attributes and methods of the Samoyed class. Note that we are not using inheritance to create a Samoyed class from a general Dog class. Here, we are giving the functionality of the Samoyed class to our Dog class.</p> <p>What is the color of my_dog? Just add</p> <pre><code>print(my_dog.color)\n</code></pre> <p>to the code above. The output will be:</p> <pre><code>white\n</code></pre> <p>We first defined the color to be \"black\", but then we used the __init__ of the Samoyed class which overwrites the color of the instantiated object.</p> <p>You can use inheritance to provide classes with extra features. Sometimes, these classes are designed with only that in mind. Mixin classes are classes that should not be instantiated, they are designed to provide methods to a child class. An example is a class to save data to a json:</p> <pre><code>import numpy as np\nimport json\n\nclass Save:\n    def save_to_json(self):\n        return json.dumps(self.__dict__, default=self.default)\n\n    @staticmethod\n    def default(obj):\n        return list(obj)\n\nclass Samoyed:\n    def __init__(self):\n        self.color = \"white\"\n        self.position = np.zeros(4)\n\n    def work(self):\n        print(\"Pulling a sledge\")\n        self.position += np.random.randint(0,5,4) + np.array([0,0,0,1])        \n\n    def look_cute(self):\n        print(\"{} is looking cute!\".format(self.name))\n\n\nclass Dog(Save, Samoyed):\n\n    def __init__(self, name, age):\n        # super().__init__()\n        Samoyed.__init__(self)\n        self.name =  name\n        self.age = age\n        self.sound = \"Waf waf\"\n        # self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nmy_dog = Dog(\"Gandalf\", 3)\nmy_dog.work()\nprint(my_dog.position)\nprint(my_dog.save_to_json())\n</code></pre> <p>Following our analogy in this example is a bit tricky... We are just adding a method to save the information of our dogs.</p> <p>Here, we also created the default static method because we got an error, the python array could not be serialized, so we use the default method to convert it to a list, which can be serialized. This is also an example of multiple inheritance. Multiple inheritance occurs when a child class takes features from more than one parent.</p>"},{"location":"python/classes/#exercise","title":"Exercise","text":"<p>Image was created with chatGPT.</p> <p>Let us continuing talking about multiple inheritance and define another breed class, SerraDaEstrela. This is a Portuguese breed, so it barks in Portuguese and has a different way of looking cute: </p> <pre><code>class SerraDaEstrela:\n    def __init__(self):\n        self.sound = \"Ao ao\"\n        self.color = \"brown\"\n\n    def look_cute(self):\n        print(\"{} is looking amazing!\".format(self.name))\n</code></pre> <p>Your task is to make a mix breed Dog class. As a breeder, you now want to specialized in creating dogs that are a mix of Samoyeds and Serra da estrela.</p> <p>Give both Samoyed and SerraDaEstrela to the Dog class. The new Dog class should have the bark and looking_cute methods from SerraDaEstrela and the work method and color attribute from the Samoyed class.</p> <p>Note: Forgot to show you the gandalf1.jpg from the look_cute method of the Samoyed class. Here it is:</p> <p></p> <p>Here is the solution:</p> <pre><code>import numpy as np\n\nclass SerraDaEstrela:\n    def __init__(self):\n        self.sound = \"Ao ao\"\n        self.color = \"brown\"\n\n    def look_cute(self):\n        print(\"{} is looking amazing!\".format(self.name))\n\nclass Samoyed:\n    def __init__(self):\n        self.color = \"white\"\n        self.position = np.zeros(4)\n\n    def work(self):\n        print(\"Pulling a sledge\")\n        self.position += np.random.randint(0,5,4) + np.array([0,0,0,1])        \n\n    def look_cute(self):\n        print(\"{} is looking cute!\".format(self.name))\n\n\nclass Dog(SerraDaEstrela, Samoyed):\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.sound = \"Waf waf\"\n        super().__init__()\n        Samoyed.__init__(self)\n\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nmy_dog = Dog(\"Gandalf\", 3)\nprint(my_dog.color)\nmy_dog.bark()\nmy_dog.look_cute()\nprint(my_dog.__dict__)\nmy_dog.work()\n</code></pre> <p>The output is:</p> <pre><code>white\nAo ao\nGandalf is looking amazing!\n{'name': 'Gandalf', 'age': 3, 'sound': 'Ao ao', 'color': 'white', 'position': array([0., 0., 0., 0.])}\nPulling a sledge\n</code></pre> <p>With this exercise you may have realized that problems can arise when a class inherites1``````6532 specific versions of the same method (example: bark method). Python deals with these problems using a specific method resolution order (MRO):</p> <p>In general, Python searches for methods and attributes in the following order:</p> <ul> <li>The current class</li> <li>The leftmost superclasses</li> <li>The superclass listed next, from left to right, up to the last superclass</li> <li>The superclasses of inherited classes</li> <li>The object class</li> </ul> <p>So, to successfully used inheritance you need to be careful with the order in which the parent classes appear in the child class. You need to be careful with the Super() function, and remember that you can always call specific methods with ParentClass.method(). You can use the __mro__ or mro() to check the mro of a class: </p> <p><pre><code>print(Dog.__mro__)\nprint(Dog.mro())\n</code></pre> gives the output</p> <pre><code>(&lt;class '__main__.Dog'&gt;, &lt;class '__main__.SerraDaEstrela'&gt;, &lt;class '__main__.Samoyed'&gt;, &lt;class 'object'&gt;)\n[&lt;class '__main__.Dog'&gt;, &lt;class '__main__.SerraDaEstrela'&gt;, &lt;class '__main__.Samoyed'&gt;, &lt;class 'object'&gt;]\n</code></pre>"},{"location":"python/classes/#composition","title":"Composition","text":"<p>You can create complex objects by combining objects that will work as components. Note that these components may not make sense as stand-alone classes.</p> <pre><code>import numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\n\nclass Samoyed:\n    def __init__(self):\n        self.color = \"white\"\n\n    def work(self):\n        print(\"Pulling a sledge\")\n        return np.random.randint(0,5,4) + np.array([0,0,0,1])        \n\n    def look_cute(self):\n        img = Image.open(\"gandalf1.jpg\")\n        img = np.asarray(img)\n        plt.imshow(img)\n        plt.show()\n\n\nclass Dog:\n    owner_name = \"Mario\"\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n        self.breed = Samoyed()\n        self.color = self.breed.color\n\n    def work(self):\n        self.position += self.breed.work()\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nmy_dog = Dog(\"Gandalf\", 3)\nmy_dog.work()\nmy_dog.breed.look_cute()\n</code></pre> <p>Here, the Samoyed class become a component of the Dog class, and its methods can now be used inside the Dog class by calling the breed attribute, which is actually an instantiation of the Samoyed class. We increased the functionality of the Dog class, and we do not have any intentions of changing the Samoyed class.</p>"},{"location":"python/classes/#inheritance-vs-composition","title":"Inheritance vs Composition","text":"<p>Inheritance establishes a relation between objects, allowing you to use methods and attributes from the parent class to the child class. You can then add extra features. Composition allows you to use a class inside another, as is. </p> <p>When one needs to use the class as it without any modification, the composition is recommended and when one needs to change the behavior of the method in another class, then inheritance is recommended. You can read more about it here.</p> <p>There are other alternatives to composition and inheritance, such as Dependency injection and Delegation.</p>"},{"location":"python/classes/#dependency-injection","title":"Dependency injection","text":"<p>With this design technique, you can provide an object\u2019s dependencies from the outside, rather than inheriting or implementing them in the object itself.  <pre><code>class Dog:\n    def __init__(self, name, breed):\n        self.name = name\n        self.breed = breed\n\nmy_dog = Dog(\"Gandalf\", Samoyed())\n</code></pre></p> <p>Note: that we provide the breed Class Samoyed when we instantiate the object.</p>"},{"location":"python/classes/#delegation","title":"Delegation","text":"<p>With this design technique, an object hands a task over to another object, which takes care of executing the task. Imagine you now want to breed cats. In our case, a cat is something very similar to a dog, that meows instead of barking:</p> <p></p> <p>Image was created with chatGPT.</p> <pre><code>import numpy as np\n\n\nclass Dog:\n    owner_name = \"Mario\"\n\n    def __init__(self, name, age):\n        self.name =  name\n        self.age = age\n        self.color = None\n        self.sound = \"Waf waf\"\n        self.position = np.zeros(4)\n\n    def walk(self):\n        print(\"Walking on four legs\")\n        self.position += np.random.randint(0,2,4) + np.array([0,0,0,1])\n\n    def bark(self):\n        print(self.sound)\n\n\nclass Cat:\n    def __init__(self, name, age):\n        self._dog = Dog(name, age)\n        self._dog.sound = \"Meow\"\n\n    def walk(self):\n        self._dog.walk()\n\n    def meow(self):\n        self._dog.bark()\n\n    def get_name(self):\n        return self._dog.get_name()\n\nmy_cat  = Cat(\"Tom\", 3)\n\nprint(my_cat.get_name())\nmy_cat.meow()\nmy_cat.walk()\n</code></pre> <p>Here we delegated all the operations related to storing data, walking, retrieving name, and making sounds to the Dog object. </p>"},{"location":"python/classes/#when-to-avoid-classes","title":"When to avoid classes","text":"<p>Classes are great and can help you model and solve complex real-world problems. However, be warned. Do not overuse classes! There are many occasions when you should avoid them, such as when you just want to store data, or when you just need to write one single method. In these occasions use a function or other python objects. </p>"},{"location":"python/classes/#further-reading","title":"Further reading","text":"<p>If you want to learn more about classes, you can use any python book, like this pythonbook, and many resources online, like this realpython. Incidentally, we use these examples to write this overview. </p>"},{"location":"python/devices/","title":"Overview of devices","text":""},{"location":"python/devices/#setup","title":"Setup","text":"<p>When you want to measure something in the lab, the first step is to consider the available equipment. Sometimes, you may find that the necessary tools are not available or are too limited for your specific needs. In such cases, you might decide to build your own experimental setup. (Image on the left was created with chatGPT.)</p> <p>In the field of photonics, there is a wide array of equipment and components that can be used to construct custom setups:</p> <ul> <li>lasers, </li> <li>beam splitters, </li> <li>optical fibers, </li> <li>mirrors, </li> <li>lenses, </li> <li>waveplates, </li> <li>modulators, </li> <li>photodetectors,</li> <li>spectrometers,</li> <li>stages,</li> <li>filters, </li> <li>and other optical elements\u2014mounts. </li> </ul> <p>These components can be combined in flexible ways to perform measurements such as transmission, reflection, absorption, photoluminescence, nonlinear optical effects, et cetera.</p> <p>Many companies specialize in manufacturing optical components and laboratory equipment. Examples of such companies are</p> <ul> <li>Zurich Instruments,</li> <li>Thorlabs, </li> <li>Newport (MKS Instruments), </li> <li>Edmund Optics, </li> <li>PI (Physik Instrumente).</li> </ul> <p>A growing number of these devices come with motorized or electronic control, and manufacturers often provide their own proprietary software as well as application programming interfaces (APIs), software development kits (SDKs), or Python libraries. This enables users to write custom scripts to automate alignment, control tunable optics, acquire data, and perform real-time adjustments\u2014making it possible to fully integrate hardware control into experimental workflows.</p> <p>Designing your own setup allows you to tailor the experiment precisely to your goals, whether it's maximizing sensitivity, optimizing spatial resolution, or synchronizing multiple light sources and detectors. It also deepens your understanding of the underlying physics and the tools themselves, which is an essential skill in experimental photonics.</p>"},{"location":"python/devices/#how-does-the-device-work","title":"How does the device work?","text":"<p>Before building your setup, you need to understand a few things though. Most importantly, how does the device work? How does a linear stage move back and forth? What are the constraints and the error on the measures or movement of a device? Luckily, most of the questions that might come to your mind will have an answer written on the manual of the device provided by the company (that you bought the device from). So our advice would be to always read these manuals.</p>"},{"location":"python/devices/#company-software","title":"Company software","text":"<p>If the device can be connected to a computer, the company that sold you the device will also provide software to use the device. Our second piece of advice is to always check it out. Without a doubt you should install it: the software will give show you directly the capabilities and constraints of the devise, and will often come with libraries, such as DLL's (Dynamic Link Library) that your computer might need to even connect or use the device. </p>"},{"location":"python/devices/#how-to-connect-with-python","title":"How to connect with python?","text":"<p>You might also want to control to the device using python (or any other programming language, though python is probably the easiest). Since this may give you more control over the flow of the experiment, over the saving and processing of the experimental data, and can also give you all the tools necessary to automate the experiment.</p> <p>To control a device with python, you will need a python package that implements the methods necessary to find the device, connect to the device, and perform the task of device, such as moving back and forwards for a linear stage or measuring a quantity for a detector. You can always write it yourself, although this might be complicated and time-consuming. Luckily, specially when working with python, there is a good change that someone else already wrote it. So, your first task is to find these packages. And then you can alter them or use as is. </p> <p>Note: Often, the packages you might write or find online will not have all the functionality provided by the company software, as these packages are not official packages. It will have methods to do the main task of the device (like moving back and forth on a linear stage) but it might lack functionality, like printing information of the device or cleaning the device. So, once again we advise you not to neglect the software provided by the company.</p>"},{"location":"python/devices/#pyserial-and-pyvisa","title":"PySerial and PyVISA","text":"<p>In order to control a device with a computer, there are many protocols, sent over many interfaces and bus systems, such as GPIB, RS-232, VXI, USB, Ethernet.</p> <p>A serial port is a serial communication interface through which information transfers in or out sequentially one bit at a time. Early personal computer used a serial port to communicate with devices, such as modems, terminals, and peripherals. Nowadays, serial ports have been replaced with more efficient interfaces, such as USB and the term serial port usually denotes hardware compliant with RS-232 serial communication standard.</p> <p>Modern devices use an integrated circuit called a Universal_asynchronous_receiver-transmitter UART to implement a serial port, though. This integrated circuit converts characters to and from asynchronous serial form, implementing the timing and framing of data specified by the serial protocol in hardware.</p> <p>PySerial is a python module that encapsulates the access for the serial port. With it, the python program in your computer can communicate with a device.</p> <p>What about the other interfaces? Whether you are using RS-232, GPIB, Ethernet, VXI, or USB, message-based communication is a standard protocol for controlling and receiving data from instruments. Because most message-based devices have similar capabilities, it is natural that the driver interface should be consistent. The Virtual instrument software architecture VISA is a widely used application programming interface in the test and measurement industry for communicating with instruments from a computer. VISA is a standard for configuring, programming, and troubleshooting instrumentation systems.</p> <p>PyVISA is both a Python wrapper for VISA shared libraries but can also serve as a front-end for other VISA implementation. In order for PyVISA to work, you need to have a suitable backend. PyVISA includes a backend that wraps the National Instruments\u2019s VISA library. If you want to use PyVISA you need to install National Instruments\u2019s VISA library or PyVISA-Py which is a pure Python implementation of the VISA standard. </p>"},{"location":"python/devices/#exercise","title":"Exercise","text":"<p>Find the manuals for the two devices we will use after the break:</p> <ul> <li>Thorlabs ELL17 linear stage</li> <li>Thorlabs PM100D power meter</li> </ul>"},{"location":"python/guideline/","title":"Installation Guideline","text":"<p>Here, we will provide you with the list of programs and modules for python you need to install for this school.</p>"},{"location":"python/guideline/#install-python-313","title":"Install python 3.13","text":"<p>Regardless of your operating system, you can download python 3.13 here. For example, for windows we would recommend you to download the recommended file for windows Windows installer (64-bit).</p> <ul> <li> <p>On windows machines you can also download it from the Microsoft store.</p> </li> <li> <p>On MacOS you can also install python through Homebrew or MacPorts:</p> </li> </ul> <p><pre><code>brew install python@3.13\n</code></pre> or  <pre><code>sudo port install python313\n</code></pre></p> <ul> <li>On linux, you can install in from the source. Alternatives methods depend on your distribution. On ubuntu try </li> </ul> <pre><code>sudo add-apt-repository ppa:deadsnakes/ppa\nsudo apt install python3.13 python3.13-venv\n</code></pre> <ul> <li> <p>on Fedora and Red Hat <pre><code>dnf install python3.13 \n</code></pre></p> </li> <li> <p>on arch linux <pre><code>sudo pacman -S python\n</code></pre></p> </li> </ul> <p>Alternatively, you can also install python using Anaconda, which is a popular and comprehensive open-source distribution of the Python and R programming languages, specifically designed for data science, machine learning, and artificial intelligence. It bundles these languages with a vast collection of data science packages, as well as tools for managing environments and packages, simplifying the process of setting up and using these technologies. </p>"},{"location":"python/guideline/#create-a-folder-pypaw2025","title":"Create a folder: PyPAW2025","text":"<p>Create a folder/directory called PyPAW2025 (from Python Photonics Automation Workshop 2025) wherever you want in your system. This will be your working folder for this workshop. Go inside the folder and open the terminal on linux or MacOs or the command prompt on Windows (start up, and look for cmd). If not already there, move into that folder using cd. Example: If you create the folder in the Desktop and your terminal or command prompt is open in your home folder, you can write:</p> <ul> <li> <p>On windows <pre><code>cd Desktop\\PyPAW2025\n</code></pre></p> </li> <li> <p>On linux and MacOS <pre><code>cd Desktop/PyPAW2025\n</code></pre></p> </li> </ul>"},{"location":"python/guideline/#create-virtual-environment-env","title":"Create virtual environment: env","text":"<p>Now, we will create a virtual environment using venv. This will make it easy to try different packages or python modules. Moreover, it will help you keep your python installation organized.</p> <ul> <li> <p>On windows: <pre><code>py -3.13 -m venv env\n</code></pre></p> </li> <li> <p>On linux and MacOS: <pre><code>python3.13 -m venv env\n</code></pre> Now you should have a folder called env inside PyPAW2025</p> </li> <li> <p>If you are using Anaconda</p> </li> </ul> <pre><code>conda create --prefix ./env  python=3.13\n</code></pre>"},{"location":"python/guideline/#activate-the-virtual-environment","title":"Activate the virtual environment","text":"<ul> <li> <p>On the windows command prompt type: <pre><code>env\\Scripts\\activate\n</code></pre></p> </li> <li> <p>On linux and MacOS: <pre><code>source env/bin/activate\n</code></pre></p> </li> <li> <p>If you are using Anaconda <pre><code>conda activate ./env\n</code></pre></p> </li> </ul> <p>If nothing failed, your current line on the terminal or command prompt should start with (env).</p>"},{"location":"python/guideline/#testing-the-virtual-environment","title":"Testing the virtual environment","text":"<p>To test the virtual environment, type python on the terminal or command prompt and press enter. The python shell should appear on the terminal. You will see something like this on ubuntu:</p> <pre><code>Python 3.13.3 (main, Apr  9 2025, 08:55:03) [GCC 13.3.0] on linux\nType \"help\", \"copyright\", \"credits\" or \"license\" for more information.\n</code></pre> <p>For windows, MacOs, or other linux distributions you should see something similar.</p> <p>Now you can type in the python shell</p> <pre><code>print(\"Hello World!\")\n</code></pre> <p>and press enter. It will output: <pre><code>Hello World!\n</code></pre></p> <p>Type exit() and press enter to leave the python shell. Your current line on the terminal or command prompt should start with (env). You can also type the previous program into a file. For that type in the terminal or command prompt</p> <ul> <li>On windows write <pre><code>notepad hello.py\n</code></pre></li> </ul> <p>On linux and MacOS write</p> <pre><code>nano hello.py\n</code></pre> <p>Now type </p> <p><pre><code>print(\"Hello World!\")\n</code></pre> In the text editor window, save and close it (Note: with nano you can do control+o to save and control+x to exit). To run this code, type in the terminal or command prompt window:</p> <pre><code>python hello.py\n</code></pre> <p>which will output: <pre><code>Hello World!\n</code></pre></p>"},{"location":"python/guideline/#update-pip","title":"Update pip","text":"<p>Now type </p> <p><pre><code>pip install --upgrade pip\n</code></pre> to update pip. On windows you might need to type</p> <p><pre><code>python.exe install --upgrade pip\n</code></pre> instead. Pip will tell you what to write if there is a problem.</p>"},{"location":"python/guideline/#python-packages","title":"Python Packages","text":"<p>Now, let us start installing some python packages. Open the terminal or command prompt and activate your environment if you close it for some reason. </p> <p>Firstly, we will install three of the most used python packages in academia <pre><code>pip install matplotlib numpy scipy\n</code></pre></p> <p>These are used to make plots, do scientific calculations, and statistical analysis (read more here numpy, scipy, and matplotlib).</p> <p>Next we need to help python to recognize and read for the usb ports of your computer. We need a library named libusb-1.0. While there are many ways to install this library, the easiest ways we found are the following.</p> <ul> <li>On windows, you need to go to libusb and mouseover Downloads and select the second option Latest Windows Binaries. Extract the file and choose the appropriate .dll. Example: Downloads\\libusb-1.0.29\\VS2022\\MS64\\dll\\libusb-1.0.dll. Copy this file and paste it in This PC\\Windows(C:)\\Windows\\System32</li> </ul> <p>-On several linux distributions, it is probably already installed. If not, just do </p> <pre><code>sudo apt install libusb-1.0\n</code></pre> <p>-On MacOs,</p> <pre><code>brew install libusb\n</code></pre> <p>Then install the python module pyusb <pre><code>pip install pyusb\npip install zeroconf psutil\n</code></pre> You can also install zeroconf and psutil. Without them, you might get some warnings when looking for devices. They are not necessary though.</p> <p>To test the pyusb installation open the python shell (by pressing python on the terminal or command prompt): and type:</p> <p><pre><code>import usb\n\nfor dev in usb.core.find(find_all=True):\n    print(dev)\n</code></pre> And press enter. The python shell should now be filled with a list of ports and information about them. Press exit() to leave the python shell.</p> <p>Now, we are ready to install PyVISA and  PySerial:</p> <pre><code>pip install PyVISA  PyVISA-py pyserial\n</code></pre> <p>If you want to use PyVISA you need to install National Instruments\u2019s VISA library or PyVISA-Py which is a pure Python implementation of the VISA standard. For this workshop PyVISA-Py is enough</p> <p>Finally, we want to install two modules to control a few Thorlabs devices, a linear stage and a powermeter:</p> <pre><code>pip install elliptec ThorlabsPM100\n</code></pre> <ul> <li> <p>On windows, you also want to install the thorlabs software for the PM100D powermeter. In particular you want to install the Thorlabs driver switcher program, that comes also with the software for the power meter. You can look for  the driver switcher at the start up.</p> </li> <li> <p>On ubuntu and similar linux distros you might not have permissions to read the devices. Use sudo or change the permissions (see this example)</p> </li> </ul> <p>Additionally, we want you to build a Graphical User Interface (GUI), for that we will use PyQT5: <pre><code>pip install PyQT5\n</code></pre></p> <p>When you work with PyQT, it is a good idea to install PyQT Designer: </p> <ul> <li> <p>On windows: <pre><code>pip install PyQT5Designer\n</code></pre></p> </li> <li> <p>On ubuntu and similar linux distros, Designer comes with</p> </li> </ul> <pre><code>sudo apt-get install qttools5-dev-tools\n</code></pre> <p>You can also install PyQT5 through apt:</p> <pre><code>sudo apt-get install python3-pyqt5  \nsudo apt-get install pyqt5-dev-tools\n</code></pre> <ul> <li>On MacOS you need to download and install QT. During the installation you need to create a QT account. It should be free. Follow this video for more details.</li> </ul>"},{"location":"python/guideline/#additional-programs","title":"Additional programs","text":""},{"location":"python/guideline/#ide","title":"IDE","text":"<p>You can use any code editor or Integrated Development Environment (IDE) to write your python programs. We would recommend visual studio code Check this for installation details. If you installed Anaconda, you can use spyder also.</p>"},{"location":"python/intro/","title":"Welcome to the photonics automation python school","text":""},{"location":"python/intro/#introduction-to-python","title":"Introduction to python","text":"<p>First, we have a couple questions for you, why is this programming language called python? (Image on the left was created with chatGPT.)</p> <p></p> <p>https://thenewstack.io/what-is-python/</p> <p>Is it because of snakes or </p> <p></p> <p>https://www.imdb.com/title/tt0063929/</p> <p>comedy?</p> <p> </p> <p>And who is this guy?</p> <p>Guido van Rossum started designing python on the Christmas season of 1989. Python was then released in 1991. Guido needed a short recognizable name for his programming language. Python came to his mind because, at the same time he was developping the language, he was also reading scripts from \"Monty python flying circus\".  </p>"},{"location":"python/intro/#what-is-python","title":"What is python?","text":"<p>Python is an object-oriented, usually interpreted, general-purpose programming language with dynamic semantics. Its high-level built in data structures, combined with strong dynamic (duck) typing and dynamic binding, make it very attractive for rapid application development. It also supports other programming paradigms, such as procedural and functional programming. </p> <p>Python combines remarkable power with very clear syntax, it incorporates modules, exceptions, and is very easy to debug. </p> <p>Python is portable, open source, and usable as an extension language for applications that need a programmable interface and as a scripting language to connect existing components together.</p> <p>You can read more here python:faq and python:essays.</p>"},{"location":"python/intro/#different-implementations-of-python","title":"Different implementations of python","text":"<p>When people talk about python, usually they are refering to the Cpython implementation (see source), managed by the non-profit organization Python Software Foundation, which develops and maintains Python standards.</p> <p>But there are other implementations, such as IronPython (written in .NET), Jython (in Java), PyPy (implementation with JIT compiler). </p>"},{"location":"python/intro/#who-uses-python","title":"Who uses python?","text":"<p>\"In 2025, Python continues to be a popular choice for a wide range of organizations and applications, including tech giants like Google, Netflix, and Facebook, as well as companies in fields like data science, web development, and AI/ML. Its versatility and ease of use make it a valuable tool for various tasks, from building web applications to analyzing data and developing AI models.\" by Google AI overview</p> <p>Python is actually the most popular choice for programming language, see PYPL PopularitY of Programming Language, and TIOBE index.</p> <p></p> <p></p> <p>https://medium.com/nerd-for-tech/top-10-python-development-company-to-hire-d83507a33755</p> <p>Python has become a prominent programming language in academia, especially in STEM fields, due to its versatility, ease of use, and extensive libraries for data analysis, machine learning, and other research areas. It's increasingly used for teaching programming in various disciplines, from introductory courses to advanced research projects. A few examples of widely used python libraries are NumPy, Pandas, Scikit-learn, TensorFlow, and PyTorch. </p>"},{"location":"python/intro/#how-to-use-python","title":"How to use python?","text":"<p>Here we will go over some python basics. </p>"},{"location":"python/intro/#hello-world","title":"Hello World","text":"<p>It all starts with a hello!</p> <pre><code>print(\"Hello World!\")\n</code></pre>"},{"location":"python/intro/#loop","title":"Loop","text":"<p>To move from A to B with a certain integer stepsize:</p> <pre><code>A = 0\nB = 20\nstepsize = 2 \nfor pos in range(A, B+1, stepsize):\n    print(pos)\n</code></pre>"},{"location":"python/intro/#write-to-a-file","title":"Write to a file","text":"<p>To write \"wavelength\" and \"intensity\" to a file use <pre><code>with open(\"data.txt\", \"w\") as f:\n    f.write(\"wavelength intensity\")\n</code></pre> or you can also use the print function <pre><code>with open(\"data.txt\", \"w\") as f:\n    print(\"wavelength intensity\", file=f)\n</code></pre></p>"},{"location":"python/intro/#read-from-a-file","title":"Read from a file","text":"<p>To read from a file use <pre><code>with open(\"data.txt\", \"r\") as f:\n    data = f.readlines()\n</code></pre></p>"},{"location":"python/intro/#modules","title":"Modules","text":"<p>To use python libraries, packages, or modules in your code, write</p> <pre><code>import glob\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom time import time\n</code></pre>"},{"location":"python/intro/#writing-and-reading-using-numpy","title":"Writing and reading using numpy","text":"<p>To write a .txt file, use numpy.savetxt</p> <p><pre><code>import numpy as np\n\nn = 20\nx = list(range(0,n))\ny = list(range(0,n*2,2))\n\nnp.savetxt('out.txt', np.c_[x,y], fmt='%1.3f', header=\"n = {}\\nx y\".format(n))\n</code></pre> to read numpy.loadtxt and readline for the header <pre><code>import numpy as np\n\ndata = np.loadtxt(\"out.txt\")\nprint(data)\n\n#Missing header\nwith open(\"out.txt\", \"r\") as f:\n    header = f.readline()\n    header += f.readline()\n\nprint(header)\n</code></pre></p> <p>You can use numpy to write to different file types, such as .npz. NPZ is a file format by numpy that provides storage of array data using gzip compression</p> <p>To write simply use numpy.savez <pre><code>import numpy as np\n\nn = 20\nx = list(range(0,n))\ny = list(range(0,n*2,2))\n\nnp.savez(\"out\", x=x, y=y, n=n)\n</code></pre></p> <p>To read we can use numpy.load. Data is some complex data type, but it can be read similarly to a dictionary</p> <pre><code>import numpy as np\n\ndata = np.load(\"out.npz\")\nfor key, val in data.items():\n    print(key, val)\nprint(data[\"n\"])\n</code></pre>"},{"location":"python/intro/#writing-and-reading-using-json","title":"Writing and reading using json","text":"<p>To write we open a .json file and write a dictionary to it <pre><code>import json\n\nn = 20\nx = list(range(0,n))\ny = list(range(0,n*2,2))\n\nwith open(\"out.json\", \"w\") as f:\n    json.dump({\"x\":x, \"y\":y, \"n\":n}, f)\n</code></pre></p> <p>To read use <pre><code>import json\n\nwith open(\"out.json\", \"r\") as f:\n    data = json.load(f)\n\nprint(data)\n</code></pre></p>"},{"location":"python/intro/#plotting","title":"Plotting","text":"<p>Here is a simple example on how to plot with matplotlib:</p> <pre><code>import numpy as np\nimport matplotlib.pyplot as plt\n\nx = np.linspace(0, np.pi, 100)\n\nplt.plot(x, np.sin(x))\nplt.show()\n</code></pre>"},{"location":"python/intro/#functions","title":"Functions","text":"<p>Here is a simple example on how to use functions:</p> <pre><code>def say_hello(name):\n    x = \"Hello {}!\".format(name)\n    print(x)\n    return x\n\nw = say_hello(\"Mario\")\nprint(say_hello(\"Gandalf\"))\n</code></pre>"},{"location":"python/intro/#python-dictionary","title":"Python dictionary","text":"<p>Here is a simple example on how to use python dictionaries:</p> <pre><code>data = {\"positions\":[0,5,10,15,20],\n        \"measurement\":[1,2,3,4,5],\n        \"step\":5\n        }\nprint(data)\nprint(data.items())\nprint(data.keys())\nprint(data.values())\n\nfor key, value in data.items():\n    print(key, value) \n</code></pre>"},{"location":"python/knife_edge/","title":"Knife-edge experiment","text":""},{"location":"python/knife_edge/#history","title":"History","text":"<p>The Foucault knife-edge test was described in 1858 by French physicist L\u00e9on Foucault as a way to measure conic shapes of optical mirrors. It measures mirror surface dimensions by reflecting light into a knife edge at or near the mirror's center of curvature. (Image on the left was created with chatGPT.)</p> <p>The Foucault knife-edge test, originally designed for testing mirror curvature, can be adapted to measure the diameter of a laser beam. </p>"},{"location":"python/knife_edge/#measuring-the-diameter-of-a-laser-beam","title":"Measuring the diameter of a laser beam.","text":"<p>https://www.cnilaser.com/Laser-Gaussian-Beam-Measurement.htm</p> <p>A simple method to determine the diameter of a laser beam is to gradually eclipse the laser beam using a sharp knife-edge. As the knife-edge intersects the beam in a direction perpendicular to the propagation axis of the beam, a photodetector measures the intensity of the unmasked portion of the beam. If the spatial profile of the laser beam is described by a Gaussian line shape, the signal measured by the detector is represented by an integrated Gaussian function. In principle, the beam diameter can be determined from such photodetector data. One approach involves electronic or numerical differentiation of the experimental data, thus reconstructing the original Gaussian profile. See this for more information. See this on for non-Gaussian beams.</p> <p>Here, we are going to perform a knife-edge scan, using the modules we have written so far, and a linear stage and a power meter devices. Below you can see all the modules we discussed previously.</p>"},{"location":"python/knife_edge/#python-module-for-the-linear-stage","title":"Python Module for the linear stage","text":"<p>The complete module discussed in Linear Stage</p> <pre><code>import elliptec\nimport sys, os\nimport time\nimport save_data\n\nclass LinearStage():\n    \"\"\" Linear stage interface\"\"\"\n\n    def __init__(self):\n        self.ports = None\n        self.devices = None\n        self._controller = None\n        self.device = None\n        self.current_position = None\n\n\n    def find_devices(self):\n        \"\"\" Lists serial port names \"\"\"\n\n        ports = elliptec.scan.find_ports()\n        self.ports = ports[:]    \n        return ports\n\n    def connect(self, idn):\n        self._controller = elliptec.Controller(idn, debug=False)\n        self._controller.port = idn\n        self.devices = elliptec.scan_for_devices(controller=self._controller)\n        self.device = elliptec.Linear(self._controller)\n        self.current_position = self.check_position()\n        return self.device.info\n\n\n    def home(self):\n        sys.stdout = open(os.devnull, 'w')\n        self.device.home()\n        sys.stdout = sys.__stdout__\n\n\n    def move(self, pos):\n        sys.stdout = open(os.devnull, 'w')\n        position = self.device.set_distance(pos)\n        sys.stdout = sys.__stdout__\n        self.current_position = position\n        return position\n\n\n    def check_position(self):\n        return self.device.get_distance()\n\n\n    def jog_and_measure(self, start=0, end=60, step=1, function=None, time_wait=1):\n\n        if not function:\n            print(\"Need funcion\")\n            return 1\n\n        position, measure = [], []\n        for pos in range(start, end+1, step):\n            position.append(self.move(pos))\n            measure.append(function())\n            time.sleep(time_wait)\n\n        save_data.with_print(position=position, measure=measure, parameters={\"step\":step})\n        return 0\n\n\nif __name__ == \"__main__\":\n\n    ls = LinearStage()\n    lls = ls.find_devices()\n    info = ls.connect(lls[0])\n    print(info)\n\n    ls.home()\n    ls.jog_and_measure(step = 5, function=time.time, time_wait=0)\n    ls.move(14)\n</code></pre>"},{"location":"python/knife_edge/#python-module-for-the-power-meter","title":"Python Module for the power meter","text":"<p>The complete module discussed in power meter:</p> <pre><code>import pyvisa\nfrom ThorlabsPM100 import ThorlabsPM100\nimport numpy as np\n\n# import warnings\n# warnings.filterwarnings('ignore')\n# pip install zeroconf psutil\n\nclass PowerMeter():\n\n    def __init__(self):\n        \"\"\"\n        A general powermeter interface.\n        \"\"\"\n\n        # self.rm = pyvisa.ResourceManager('@py')\n        self.rm = pyvisa.ResourceManager()\n        self.powermeters = {}\n        self.inst = None\n        self.powermeter = None\n        self.lastAcq = None\n        self.trace = np.zeros(100)\n        self.parameters = {\"wavelength\": None,\n                           \"background\": 0,\n                           \"unit\": None}\n\n        self._str_wavelength = 'sense:corr:wav'\n        self._str_power = 'power:dc:unit '\n\n    def find_powermeter(self):\n        \"\"\"Find all available ports with Power Meter: PM100 attached.\"\"\"\n        for addr in self.rm.list_resources():\n            try:\n                name = self.rm.open_resource(addr).query('*IDN?')\n                if 'PM100' in name:\n                    self.powermeters[name] = addr\n            except:\n                pass\n        return list(self.powermeters.keys())\n\n    def connect(self, idn):\n        \"\"\" Connects to the power meter attached to port idn \n            idn example: list(self.powermeters.keys())[0] \n        \"\"\"\n        self.inst = self.rm.open_resource(self.powermeters[idn])\n        self.inst.read_termination = '\\n'\n        self.inst.write_termination = '\\r\\n'\n        self.powermeter = ThorlabsPM100(inst=self.inst)\n        self.powermeter.configure.scalar.power()\n        self.lastAcq = self.powermeter.read\n\n        self.get_wavelength()\n        self.get_unit()\n\n        print('Connected to powermeter: {}'.format(idn))\n\n    def read(self, pure=False, printval=False):\n        \"\"\" Make measurement: in this case, read power, if \n            pure is False, subtracts the background to the measurement\n\n        \"\"\"\n        if pure:\n            val = self.powermeter.read\n        else:\n            val = self.powermeter.read - self.parameters[\"background\"]\n        self.lastAcq = val\n        self.trace = np.append(self.trace[1:], val)\n        if printval:\n            print('Measure: {} {}'.format(val, self.parameters[\"unit\"]))\n        return val\n\n    def get_background(self):\n        \"\"\" Make a background measurement \"\"\"\n        self.parameters[\"background\"] = self.read(pure=True)\n        self.read()\n        print('Background: {} {}'.format(self.parameters[\"background\"], self.parameters[\"unit\"]))\n\n    def get_wavelength(self):\n        \"\"\" Get current wavelength used by the power meter\"\"\" \n        wl = self.inst.query(self._str_wavelength+'?')\n        self.parameters[\"wavelength\"] = wl\n        print('Wavelength: {} {}'.format(wl, \"nm\"))\n        return wl\n\n    def set_wavelength(self, wl):\n        \"\"\" Change wavelength used by the powermeter to calculate the power\"\"\"\n        self.inst.write(self._str_wavelength+' '+str(int(wl)))\n        return self.get_wavelength()\n\n    def get_unit(self):\n        \"\"\" Get current unit used by the power meter\"\"\" \n        u = self.powermeter.sense.power.dc.unit\n        self.parameters[\"unit\"] = u     \n        return u \n\n    def set_unit(self, unit):\n        \"\"\" Set units of the power meter, allowed units: W or dBm\"\"\"\n        if unit not in ['W', 'dBm']:\n            print(\"Unit must be W or dBm\")\n        else:\n            self.inst.write(self._str_power+unit)\n        return self.get_unit()\n\n    def switch_unit(self):\n        \"\"\" Switch units of powermeter between dBm and W\"\"\"\n        if self.parameters[\"unit\"] == 'W':\n            self.inst.write(self._str_power+'dBm')\n        else:\n            self.inst.write(self._str_power+'W')\n        return self.get_unit()   \n\nif __name__ == \"__main__\":    \n    #initialize class             \n    pm = PowerMeter()\n\n    #Find powermeters and connect to first one\n    lpm = pm.find_powermeter()\n\n    print(lpm)\n    pm.connect(lpm[0])\n\n\n    #Measure, get background and measure again\n    pm.read(printval=True)\n    pm.get_background()\n    pm.read(printval=True)\n\n    pm.get_wavelength()\n\n    pm.switch_unit()\n    pm.read(printval=True)\n    pm.switch_unit()\n    pm.read(printval=True)\n</code></pre>"},{"location":"python/knife_edge/#save_data-module","title":"Save_data module","text":"<p>The complete module discussed in save data</p> <pre><code>def with_print(parameters={}, **kwargs):\n    \"\"\" Print parameters and measurements into a file, slightly organized\"\"\"\n    for key, val in parameters.items():\n        print(\"#\", \"%s: %s\" % (key, val))\n    print(\"#\", *kwargs.keys())\n    for row in zip(*kwargs.values()):\n        print(*row)\n\ndef with_print_dump(**kwargs):\n    \"\"\" Print data, not organized \"\"\"\n    print(kwargs)\n\ndef with_print_fancy(**kwargs):\n    \"\"\" print data after separating lists of measurements from parameters\"\"\"\n\n    print_as_list = []\n    for key, val in kwargs.items():\n        if not isinstance(val, list):\n            print(\"#\", \"%s: %s\" % (key, val))\n        else:\n            print_as_list.append(key)\n\n    print(\"#\", *print_as_list)\n    for row in zip(*(kwargs[i] for i in print_as_list)):\n        print(*row) \n\n\ndef to_file(filename = \"out\", parameters={}, **kwargs):\n    \"\"\" save data into a .txt file, it is basically function:with_print but we redirect the output to the file\"\"\" \n    filename = filename + \".txt\"\n    with open(filename, \"w\") as f:\n        for key, val in parameters.items():\n            print(\"#\", \"%s: %s\" % (key, val), file=f)\n        print(\"#\", *kwargs.keys(), file=f)\n        for row in zip(*kwargs.values()):\n            print(*row, file=f)\n\ndef with_json(filename = \"out\", **kwargs):\n    \"\"\" write data into a json file\"\"\"\n    import json\n\n    filename = filename + \".json\"\n\n    with open(filename, \"w\") as f:\n        json.dump(kwargs, f)\n\ndef with_numpy(filename = \"out\", parameters={}, **kwargs):\n    \"\"\" Write data to a .txt file with numpy\"\"\" \n    import numpy as np\n\n    filename = filename + \".txt\"\n    header = \"\"\n    for key, val in parameters.items():\n        header += \"{}: {} \\n\".format(key, val)\n    header += \" \".join(kwargs.keys())\n\n    np.savetxt(filename, np.c_[ *kwargs.values() ], header=header)\n</code></pre>"},{"location":"python/knife_edge/#plot-module","title":"Plot module","text":"<p>The complete program discussed in plot data:</p> <pre><code>import json\nimport glob\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# find the file containig the data\nfilenames = glob.glob(\"out*json\")\nprint(filenames)\n\n# open the file and get the data\nwith open(filenames[-1], \"r\") as f:\n    data = json.load(f)\n\n# check what is in the file\nprint(data.keys())\n\n# treat the data if necessary\ny = np.array(data[\"measurements\"])\ny *= 1000 # scale to change units, plot looks better\n\n# factor = y[0]           # remove background if necessary\n# y = (y - factor)*1000\n\n# make a nice plot for the data\nplt.rcParams.update({'font.size': 15})\nfig, ax = plt.subplots(figsize=(8,8))\nax.plot(data[\"positions\"], y, label=\"Step = {} mm\".format(data[\"parameters\"][\"step\"]))\nax.legend()\nax.set_xlabel(\"Position (mm)\")\nax.set_ylabel(\"Power (mW)\")\nax.tick_params(axis='both', direction='in', top=True, right=True)\n\n# show the plot or save it into a file\n#plt.show()\nplt.savefig(\"my_plot_{}.png\".format(data[\"parameters\"][\"step\"]))\n</code></pre>"},{"location":"python/knife_edge/#exercise","title":"Exercise","text":"<p>Use the modules or programs above and write a knife_edge experiment class with python.</p> <p></p> <p>Here is the solution:</p> <pre><code>import my_powermeter as mpm\nimport my_linear as mls\nimport time\nimport datetime\nimport save_data\n\nclass KnifeEdge:\n\n    \"\"\" Class to perform knife-edge experiment \"\"\"\n\n    def __init__(self):\n        self.powermeter = mpm.PowerMeter()\n        self.linear_stage = mls.LinearStage()\n        self.parameters = {            # parameters from the linear stage\n            \"start\": 0,\n            \"end\":   60,\n            \"step\":  1, \n            \"sleep\": 0.5 \n        }\n        self.positions = []\n        self.measurements = []\n\n        # First we need to find the devices\n        lpm = self.powermeter.find_powermeter()\n        lls = self.linear_stage.find_devices()\n\n\n        # Second, attempt to connect to the devices\n        try:\n            self.powermeter.connect(lpm[0])\n        except:\n            print(\"Could not connect to powermeter\")\n            print(lpm)\n            return \n\n        try:\n            self.linear_stage.connect(lls[0])\n        except:\n            print(\"Could not connect to linear stage\")\n            print(lls)\n            return\n\n\n    def initialize(self):\n        \"\"\" Home the linear stage and measure the backgroung of the powermeter \"\"\"\n        self.linear_stage.home()\n        self.powermeter.get_background()\n\n    def get_parameters(self):\n        \"\"\" Obtain parameters from the linear stage and from the powermeter \"\"\"\n        for key, val in self.parameters.items():\n            print(\"%s: %s\" % (key, val))\n        for key, val in self.powermeter.parameters.items():\n            print(\"%s: %s\" % (key, val))\n        return self.parameters, self.powermeter.parameters\n\n    def set_parameters(self, start=0, end=60, step=1, sleep=0, \n                      pm_unit='W', pm_wl=400):\n        \"\"\" Function to change the experiment parametes \"\"\"\n        self.parameters[\"start\"] = start\n        self.parameters[\"end\"] = end\n        self.parameters[\"step\"] = step\n        self.parameters[\"sleep\"] = sleep\n\n        self.powermeter.set_wavelength(pm_wl)\n        self.powermeter.set_unit(pm_unit)\n        return self.get_parameters()\n\n    def run(self):\n        \"\"\" Function to run the experiment itself, creates a file with parametes and the measured values \"\"\"\n\n        # first get a file name with the current date and time\n        filename = \"out_\"+str(datetime.datetime.now()).replace('.','_').replace(' ', '_').replace(':', '_')\n\n        # loop over the possible positions of the linear stage\n        for pos in range(self.parameters[\"start\"], \n                         self.parameters[\"end\"], self.parameters[\"step\"]):\n\n            # move the stage and store position\n            self.positions.append(self.linear_stage.move(pos))\n            # measure the power\n            self.measurements.append(self.powermeter.read()) \n            # wait for a bit, just in case\n            time.sleep(self.parameters[\"sleep\"])\n\n            # save parametes and measurements to file at every iteration, in case there is a crash interruption\n            save_data.with_json(filename=filename,\n                                parameters=self.parameters, \n                                pm_parameters=self.powermeter.parameters, \n                                positions=self.positions, \n                                measurements=self.measurements)       \n\n\nexp = KnifeEdge()\n# exp.initialize()\n# exp.set_parameters()\n\nexp.get_parameters()\nexp.run()\nprint(exp.__dict__)\n</code></pre>"},{"location":"python/linear_stage/","title":"Linear stages","text":""},{"location":"python/linear_stage/#overview","title":"Overview","text":"<p>A linear stage is a component of a precise motion system used to restrict an object to a single axis of motion.  (Image on left the as created with chatGPT.)</p> <p>There are several linear stages you can use in your experiments: they have different designs and are suitable for different travel ranges. Here, we will take a look at the Thorlabs: ELL17 linear stage.</p>"},{"location":"python/linear_stage/#thorlabs-ell17","title":"Thorlabs: ELL17","text":"<p>This component uses piezoelectric motors to move the actual stage in a range of 48 mm, with a position accuracy of 50 \u03bcm. Here, is a picture:</p> <p></p> <p>You can clearly see the linear stage attached to a circuit board, some screw slots, and the piezo motors. This last one might have confused you a bit, so let us take a look at the motor </p> <p> and its parts </p> <p>https://www.thorlabs.com/newgrouppage9.cfm?objectgroup_id=10461&amp;pn=ELL17</p>"},{"location":"python/linear_stage/#how-does-it-work","title":"How does it work?","text":"<p>The main principle behind these kinds of motors, is that when an electric field is applied to a piezoelectric material, the material will change shape. The word piezo is derived from the Greek word for pressure. The motion of the linear stage is then controlled by forcing the piezoelectric elements to vibrate at specific ultrasonic frequencies.</p> <p>The motor is operated by driving it at one of its two resonance frequencies. A voltage signal oscillating at an ultrasonic frequency is applied to the piezoelectric chip, which responds by expanding less than a micron and then contracting back to its original dimensions at the frequency of the driving signal. This continuous change of the chip's volume causes a vibration in the aluminum resonator housing. When the vibration is at one of the resonator's resonance frequencies, a pushing motion results at the tip of the motor. When the vibration is at the other resonance frequency a pulling motion is observed.</p> <p>So, for each motor, there is an ultrasonic resonant frequency that will push the stage forward, and another that will pull the stage backward. Operating a motor at one of its resonance frequencies causes the tip of the motor to continuously cycle in a tight clockwise elliptical path. When the motor is driven at its other resonant frequency, the tip of the motor cycles through that same path in a counterclockwise direction. Both resonant frequencies are around 100 kHz. The total displacement at the tip of motor is a function of the mechanical load it is driving, and the voltage supplied to the piezo element. In the case of no loading and a 5 V maximum driving voltage at a resonant frequency, the tip of the motor expands and contracts by a few microns while tracing the elliptical path.</p> <p>The purpose of the spring is to maintain constant contact between the tip of the resonator and the driven item</p> <p>To complement this explanation, take a look at this video</p> <p>An interface board can be used to supply power to the linear stage and to move the stage forward and backward in increments (2 mm default). The interface board can also be used to connect the linear stage to a computer.</p> <p>Note on the resonant frequencies: It is important to search for the optimal resonant frequencies, this can be done at any time and should be done after changes in loading or ambient temperature.</p> <p>Finally, here is a picture that shows and example of a setup that includes this linear stage and the interface board:</p> <p></p>"},{"location":"python/linear_stage/#company-software-and-manual","title":"Company software and manual","text":"<p>In this day and age, it is customary for the selling companies to provide not only a user manual, but also software that you can use in your computer to control the device. Thorlabs provides not only the Elliptec System Software, but also the Communications Protocol manual, which details the communication commands for the Elliptec software package. As discussed previously, you should always read and inspect these manuals and software. They will provide you with helpful information, such as </p> <ul> <li>Capabilities and constrains of the device,  </li> <li>Safety and environmental limits (example: Maximum altitude of 2000 m),</li> <li>Cleaning and usage details (example: Position Error Compensation).</li> </ul> <p>Here is a print screen to show you what the software for the linear stage looks like:</p> <p></p> <p>\"Commands are entered in the Sequencer command / wait order section located at the center-left of the GUI. An example of a sequence of commands that might be sent to the device is Agj to get the jog step size of the stage at address A, Asj0000200 to set the jog step size as 0.25 mm, and Abw to jog the stage at address A backward by 0.25 mm. The command As1 is used to perform the frequency search that will identify the optimal resonant frequencies, for the current operating conditions, for Motor 1 at address A.\" Protocol data is sent in ASCII HEX format, while module addresses and commands are mnemonic character (no package length is sent). Modules are addressable (default address is \u201c0\u201d) and addresses can be changed and saved using a set of commands. Lower case commands are sent by user while upper case commands are replies by the module. (Taken from the device page in the Thorlabs website provided above.)</p>"},{"location":"python/linear_stage/#how-to-connect-with-python","title":"How to connect with python?","text":"<p>One of the beauties of python, is that when you need a particular piece of code to perform a certain task, there is a good chance that someone already did it and distributed it online. In this case we want to find a python package to control this ELL17 linear stage. A quick google search will show you the elliptec python package. We will use it to control the ELL17 with our computers, and the package will take care of the communication with the device, so that we do not have to write any ASCII HEX messages ourselves.</p> <p>Keep in mind that there are 3 important methods we must implement: </p> <ul> <li>Find the device.</li> <li>Connect to the device.</li> <li>Perform the task. In this case, move back and forwards</li> </ul>"},{"location":"python/linear_stage/#find-the-device","title":"Find the device","text":"<p>For this we will use Pyserial to find the port to which the linear stage is connected</p> <p><pre><code>import serial.tools.list_ports as listports\nlistports.comports()\n</code></pre> This will list you all possible ports. You can limit the search to look for devices connected with USB or with a UART protocol using conditions:</p> <pre><code>import serial as s\nimport serial.tools.list_ports as listports\n\ndef find_linear_stage(self):\n    \"\"\" Lists serial port names \"\"\"\n\n    ports = []\n    possible_ports = listports.comports()\n    for p in possible_ports:\n        if \"UART\" in p.description or \"USB\" in p.description:\n            ports.append(p.device)\n    return ports\n</code></pre> <p>Or you can look for serial_number and attempt to make a connection, this is what the elliptec package does:</p> <pre><code>import serial as s\nimport serial.tools.list_ports as listports\n\ndef find_ports():\n    \"\"\"Find all available ports with an Elliptec device connected.\"\"\"\n    avail_ports = []\n    for port in listports.comports():\n        if port.serial_number:\n            try:\n                connection = s.Serial(port.device)\n                connection.close()\n                avail_ports.append(port)\n            except (OSError, s.SerialException):\n                print(f\"{port.device} unavailable.\\n\")\n    port_names = [port.device for port in avail_ports]\n    return port_names\n</code></pre> <p>You can then just use their function:</p> <pre><code>import elliptec\nports = elliptec.scan.find_ports()\n</code></pre> <p>Now, you might want to organize your code differently. You might want to have an object to represent the linear stage, or even built a GUI of your own for the linear stage. Or you might want to build an interface for different stages, or for linear stages from different companies. So, it might be handy to place this code inside a python class:</p> <pre><code>import elliptec\n\nclass LinearStage():\n    \"\"\" Linear stage interface\"\"\"\n\n    def __init__(self):\n        self.ports = None\n\n\n    def find_devices(self):\n        \"\"\" Lists serial port names \"\"\"\n\n        ports = elliptec.scan.find_ports()\n        self.ports = ports[:]    \n        return ports\n</code></pre>"},{"location":"python/linear_stage/#connect-to-the-device","title":"Connect to the device","text":"<p>Now that we found a list of ports that have a device attached to it, i.e. we found a list of USB ports that have a USB cable that is also attached to a device. Now we need to connect to it:</p> <pre><code>import elliptec\n\n\nclass LinearStage():\n    \"\"\" Linear stage interface\"\"\"\n\n    def __init__(self):\n        self.ports = None\n        self.device = None\n        self._controller = None\n        self.device = None\n\n\n    def find_devices(self):\n        \"\"\" Lists serial port names \"\"\"\n\n        ports = elliptec.scan.find_ports()\n        self.ports = ports[:]    \n        return ports\n\n    def connect(self, idn):\n        \"\"\" Connect to a device, location is provided by port \n            identifier idn (example: ports[0]) \n        \"\"\"\n        self._controller = elliptec.Controller(idn, debug=False)\n        self._controller.port = idn\n        self.devices = elliptec.scan_for_devices(controller=self._controller)\n        self.device = elliptec.Linear(self._controller)\n        return self.device.info\n</code></pre> <p>Here, we added the connect method. This method requires idn, which is the identifier for the port that we found previously: in your code: ports[0]. Then we have some lines that may seem confusing at first, because you do not know how the elliptec package is organized. When you have a chance go take a look. A short explanation is elliptec.Controller(idn) will attempt a connection to the device. Controller is just a general class, that provides common and basic functionality. The actual python class that provides methods to control the linear stage is Linear which we instantiate in the last line. The line self._controller.port = idn is required due to a bug in the scan_for_devices method we call next. This method will provide you with information from the device, such as the \"ELL17\" identifier.</p>"},{"location":"python/linear_stage/#perform-the-task","title":"Perform the task","text":"<p>Now we need to move the stage.</p> <p><pre><code>import elliptec\nimport sys, os\n\nclass LinearStage():\n    \"\"\" Linear stage interface\"\"\"\n\n    def __init__(self):\n        self.ports = None\n        self.devices = None\n        self._controller = None\n        self.linear = None\n\n    def find_devices(self):\n        \"\"\" Lists serial port names \"\"\"\n\n        ports = elliptec.scan.find_ports()\n        self.ports = ports[:]    \n        return ports\n\n    def connect(self, idn):\n        \"\"\" Connect to a device, location is provided by port \n            identifier idn (example: ports[0]) \n        \"\"\"\n        self._controller = elliptec.Controller(idn, debug=False)\n        self._controller.port = idn\n        self.devices = elliptec.scan_for_devices(controller=self._controller)\n        self.device = elliptec.Linear(self._controller)\n        return self.device.info\n\n    def move(self, pos):\n        \"\"\" Moves the stage to desired position pos \"\"\"\n        sys.stdout = open(os.devnull, 'w')\n        position = self.linear.set_distance(pos)\n        sys.stdout = sys.__stdout__\n        return position \n</code></pre> Here, we are just using the set_distance() method from the Elliptec class Linear. The lines with sys are here to suppress some messages from the set_distance() method.</p> <p>Usually, you might also want to define a homing function to place the stage at a rest or initial position for the measurements. You can do that with the Linear.home() method from the package.</p>"},{"location":"python/linear_stage/#exercise","title":"Exercise","text":"<p>Make a class method for the linear_stage class that moves the stage between 2 different positions, according to a given step size. At every step it takes a measurement (using a given function) and waits 1 second. </p> <pre><code>def jog_and_measure(self, start=0, end=60, step=1, function=None, wait_time=1):\n        ... # you write this\n</code></pre> <p>Hint: Pseudo code</p> <pre><code>Loop over the desired positions according to step size: step\n    move the stage\n    measure the desired quantity using the provided function\n    print or save values\n    wait for wait_time seconds \n</code></pre> <p></p> <p>Here is the solution:</p> <pre><code>import time\n\n# this is suposed to be included inside the class LinearStage\n\ndef jog_and_measure(self, start=0, end=60, step=1, function=time.time, wait_time=1):\n\n    for pos in range(start, end+1, step):\n        position = self.move(pos)\n        measure = function()\n        print(position, measure)\n        time.sleep(wait_time=1)\n    return 0\n</code></pre>"},{"location":"python/powermeter/","title":"Power Meters","text":""},{"location":"python/powermeter/#overview","title":"Overview","text":"<p>Optical power meters are devices that measure that power of the incident light. (Image on the left was created with chatGPT.)</p> <p>There are several optical power meters you can use in your experiments: they have different designs and can be attached to different sensors. Here, we will take a look at the Thorlabs: PM100D power meter or the PM100A.</p>"},{"location":"python/powermeter/#thorlabs-pm100","title":"Thorlabs: PM100","text":"<p>The PM100 handheld optical power and energy meter is designed to measure the optical power of laser light or other monochromatic or near monochromatic light sources and the energy of pulsed light sources.</p> <p></p>"},{"location":"python/powermeter/#how-does-it-work","title":"How does it work?","text":"<p>A sensor is attached to the power meter in order to produce an electric current from the incident light, i.e., a sensor is used to somehow convert photons into electrons. Then, this signal goes into the power meter, where it is amplyfied, filtered, digitalized, and used to calculate the power of the incident light. Depending on the process used to create the electrical current, the calculations will be different. Finally, the power is displayed in the screen of the power meter or in your computer. </p> <p></p> <p>There are different types of sensors you can use. Two examples are:</p> <ul> <li> <p>Photodiode sensors: these sensors rely on the usage of semiconductores in a PIN junction to produce electrons after absorbing photons, see photoelectric and photovoltaic effect for more information. The power of the incident light is proportional to the electric current generated and inversely dependent on the photodiode responsivity, that depends on the wavelength of the incident light. That is why it is important to provide the wavelength to the power meter.</p> </li> <li> <p>Thermal sensors: these sensors rely on the usage of dissimilar metals (thermocouples) to create a temperature gradient after absorbing photons. The temperature gradient is then responsible for charge carriers to flow from the warmer to the colder side, see Thermoelectric effect and Seebeck effect for more information. The power of the incident light is proportional to the voltage generated and inversely proportional to the sensitivity of the detector, which depends on the absorption coefficient of the coating layer. Higher absorption coefficients, lead to more heat and higher generated voltages. </p> </li> </ul> <p>Different types of sensors will work better for different light sources, wavelengths and power of the incident light. For example, Photodiode sensors are designed for power measurements of monochromatic or near-monochromatic sources, as they have a wavelength dependent responsivity, while thermal sensors are suitable for power measurements of broadband sources such as LEDs and SLDs.</p> <p>Here is a picture of a thermal sensor:</p> <p></p> <p>and one of a photodiode sensor:</p> <p></p> <p>Another important part of the explanation of how the power meter works is the calibration. Device calibration consists of verifying the measurement accuracy of a device and adjusting for any measurement error. For power meters, there are special setups that use references to ensure that the sensitivity or responsivity of the sensor is correctly determined, which allows to calculate the power of the incident light based on the electrical current produced by the sensor.</p> <p>To complement this explanation, take a look at these videos: video1,video2.</p>"},{"location":"python/powermeter/#company-software-and-manual","title":"Company software and manual","text":"<p>For the PM100D power meter, Thorlabs provides an PM100D and an optical power monitor operation manuals. Check them out when you have time. These material are very important, because they provide you with useful information, such as capabilities and constrains of the device:</p> <p></p> <p>The software looks like this:</p> <p></p>"},{"location":"python/powermeter/#how-to-connect-with-python","title":"How to connect with python?","text":"<p>A quick google search will show you the ThorlabsPM100  python package.</p> <p>Once again, there are 3 important methods we must implement: </p> <ul> <li>Find the device.</li> <li>Connect to the device.</li> <li>Perform the task. In this case, read the power displayed in the power meter.</li> </ul>"},{"location":"python/powermeter/#find-the-device","title":"Find the device","text":"<p>In this example, we are going to use PyVISA for the communication between the device and our computer.</p> <pre><code>import pyvisa\nfrom ThorlabsPM100 import ThorlabsPM100\nimport numpy as np\n\n\nclass Powermeter():\n\n    def __init__(self):\n        \"\"\"\n        A general powermeter interface.\n        \"\"\"\n\n        # self.rm = pyvisa.ResourceManager('@py')\n        self.rm = pyvisa.ResourceManager()\n        self.powermeters = {}\n\n    def find_powermeter(self):\n        \"\"\"Find all available ports with Power Meter: PM100 attached.\"\"\"\n        for addr in self.rm.list_resources():\n            try:\n                name = self.rm.open_resource(addr).query('*IDN?')\n                if 'PM100' in name:\n                    self.powermeters[name] = addr\n            except:\n                pass\n        return list(self.powermeters.keys())\n</code></pre> <p>The process is similar to the one we use to check the USB ports with Pyserial used in the Linear stage section. We get a list of possible ports with list_resources() from the pyvisa.ResourceManager() and we perform a query to look for the identifier of the device that we called name. Then we just confirm that the device in question is the PM100 power meter.</p>"},{"location":"python/powermeter/#connect-to-the-device","title":"Connect to the device","text":"<p>Now we need to connect to one of the ports found.</p> <pre><code>import pyvisa\nfrom ThorlabsPM100 import ThorlabsPM100\nimport numpy as np\n\n\nclass Powermeter():\n\n    def __init__(self):\n        \"\"\"\n        A general powermeter interface.\n        \"\"\"\n\n        # self.rm = pyvisa.ResourceManager('@py')\n        self.rm = pyvisa.ResourceManager()\n        self.powermeters = {}\n        self.inst = None\n        self.powermeter = None\n        self.parameters = {\"wavelength\": None,\n                           \"background\": 0,\n                           \"unit\": None}\n\n        self._str_wavelength = 'sense:corr:wav'\n        self._str_power = 'power:dc:unit '\n\n    def find_powermeter(self):\n        \"\"\"Find all available ports with Power Meter: PM100 attached.\"\"\"\n        for addr in self.rm.list_resources():\n            try:\n                name = self.rm.open_resource(addr).query('*IDN?')\n                if 'PM100' in name:\n                    self.powermeters[name] = addr\n            except:\n                pass\n        return list(self.powermeters.keys())\n\n\n    def connect(self, idn):\n        \"\"\" Connects to the power meter attached to port idn \n            idn example: list(self.powermeters.keys())[0] \n        \"\"\" \n        self.inst = self.rm.open_resource(self.powermeters[idn])\n        self.inst.read_termination = '\\n'\n        self.inst.write_termination = '\\r\\n'\n        self.powermeter = ThorlabsPM100(inst=self.inst)\n        self.powermeter.configure.scalar.power()\n\n        self.get_wavelength()\n        self.get_unit()\n\n        print('Connected to powermeter: {}'.format(idn))\n\n    def get_wavelength(self):\n        \"\"\" Retrieve the wavelength selected in the power meter \"\"\"\n        wl = self.inst.query(self._str_wavelength+'?')\n        self.parameters[\"wavelength\"] = wl\n        print('Wavelength: {} {}'.format(wl, \"nm\"))\n        return wl\n\n    def get_unit(self):\n        \"\"\" Retrieve the units selected in the power meter \"\"\"\n        u = self.powermeter.sense.power.dc.unit\n        self.parameters[\"unit\"] = u     \n        return u \n</code></pre> <p>Here, open_resource returns an instrument (class in Pyvisa) for the resource name provided. Then we provide information for read and write of the device, and finally we connect to the power meter using the ThorlabsPM100 class. The next line (self.powermeter.configure.scalar.power()) is to configure the device to measure power. And then, we confirm the wavelength and the units that the power meter is currently using.</p> <p>We also added methods to get the wavelength and the units that the power meter is currently using. Note: The wavelength is used in the conversion from optical power to photocurrent for a photodiode sensor. Remember that the photodiode responsivity depends on the wavelength. </p>"},{"location":"python/powermeter/#perform-the-task","title":"Perform the task","text":"<p>For the power meter, the task is to read or measure a value:</p> <pre><code>import pyvisa\nfrom ThorlabsPM100 import ThorlabsPM100\nimport numpy as np\n\n\nclass Powermeter():\n\n    def __init__(self):\n        \"\"\"\n        A general powermeter interface.\n        \"\"\"\n\n        # self.rm = pyvisa.ResourceManager('@py')\n        self.rm = pyvisa.ResourceManager()\n        self.powermeters = {}\n        self.inst = None\n        self.powermeter = None\n        self.parameters = {\"wavelength\": None,\n                           \"background\": 0,\n                           \"unit\": None}\n        self.lastAcq = None\n        self.trace = np.zeros(100)\n        self._str_wavelength = 'sense:corr:wav'\n        self._str_power = 'power:dc:unit '\n\n    def find_powermeter(self):\n        \"\"\"Find all available ports with Power Meter: PM100 attached.\"\"\"\n        for addr in self.rm.list_resources():\n            try:\n                name = self.rm.open_resource(addr).query('*IDN?')\n                if 'PM100' in name:\n                    self.powermeters[name] = addr\n            except:\n                pass\n        return list(self.powermeters.keys())\n\n\n    def connect(self, idn):\n        \"\"\" Connects to the power meter attached to port idn \"\"\"\n        # idn example: list(self.powermeters.keys())[0]  \n        self.inst = self.rm.open_resource(self.powermeters[idn])\n        self.inst.read_termination = '\\n'\n        self.inst.write_termination = '\\r\\n'\n        self.powermeter = ThorlabsPM100(inst=self.inst)\n        self.powermeter.configure.scalar.power()\n\n        self.get_wavelength()\n        self.get_unit()\n\n        print('Connected to powermeter: {}'.format(idn))\n\n    def get_wavelength(self):\n        \"\"\" Retrieve the wavelength selected in the power meter \"\"\"\n        wl = self.inst.query(self._str_wavelength+'?')\n        self.parameters[\"wavelength\"] = wl\n        print('Wavelength: {} {}'.format(wl, \"nm\"))\n        return wl\n\n    def get_unit(self):\n        \"\"\" Retrieve the units selected in the power meter \"\"\"\n        u = self.powermeter.sense.power.dc.unit\n        self.parameters[\"unit\"] = u     \n        return u \n\n    def read(self, printval=False):\n        \"\"\" reads the power displayed in the power meter \"\"\"\n        val = self.powermeter.read\n        self.lastAcq = val\n        self.trace = np.append(self.trace[1:], val)\n        if printval:\n            print('Measure: {} {}'.format(val, self.parameters[\"unit\"]))\n        return val\n</code></pre> <p>Here, we are using the read method from the ThorlabsPM100 class and returning the value measured val. We are also saving it in a list and as the last acquired value, you will use these variables tomorrow.</p>"},{"location":"python/powermeter/#additional-methods","title":"Additional methods:","text":"<p>It might be convenient to define methods to change or set units and to set wavelengths:</p> <pre><code>    \"\"\" This methods should be included in the PowerMeter class\"\"\"\n\n    def set_wavelength(self, wl):\n        \"\"\" Sets wl as the wavelength in the Power Meter\"\"\"\n        self.inst.write(self._str_wavelength+' '+str(int(wl)))\n        return self.get_wavelength()\n\n    def set_unit(self, unit):\n        \"\"\" Sets units to W or dBm\"\"\"\n        if unit not in ['W', 'dBm']:\n            print(\"Unit must be W or dBm\")\n        else:\n            self.inst.write(self._str_power+unit)\n        return self.get_unit()\n\n    def switch_unit(self):\n        \"\"\" Switches between the units\"\"\"\n        if self.parameters[\"unit\"] == 'W':\n            self.inst.write(self._str_power+'dBm')\n        else:\n            self.inst.write(self._str_power+'W')\n        return self.get_unit()    \n</code></pre>"},{"location":"python/powermeter/#exercise","title":"Exercise","text":"<p>Create a get_background method that will read the background and add it to the class parameters. Then change the read method in order to be able to make normal measurements and measurements where you subtract the background. </p> <p></p> <p>Here is the solution:</p> <pre><code>\"\"\" This methods should be included in the PowerMeter class\"\"\"\n\n    def read(self, pure=False, printval=False):\n        if pure:\n            val = self.powermeter.read\n        else:\n            val = self.powermeter.read - self.parameters[\"background\"]\n        self.lastAcq = val\n        self.trace = np.append(self.trace[1:], val)\n        if printval:\n            print('Measure: {} {}'.format(val, self.parameters[\"unit\"]))\n        return val\n\n    def get_background(self):\n        self.parameters[\"background\"] = self.read(pure=True)\n        self.read()\n        print('Background: {} {}'.format(self.parameters[\"background\"], self.parameters[\"unit\"]))\n</code></pre>"},{"location":"python/save_plot_data/","title":"How to save and plot data?","text":""},{"location":"python/save_plot_data/#jog-and-measure","title":"Jog and measure","text":"<p>(Image on the left was created with chatGPT.) In the exercise from linear the linear stage section, you wrote this method for our LinearStage class:</p> <pre><code>import time\n\ndef jog_and_measure(self, start=0, end=60, step=1, \n                    function=time.time, wait_time=1):\n\n    for pos in range(start, end+1, step):\n        position = self.move(pos)\n        measure = function()\n        print(position, measure)\n        time.sleep(wait_time=1)\n    return 0\n</code></pre> <p>This works! But we might want to do more operations on the lists of measurements and positions. Also depending on your experiment, you might want to save the positions and measurements at the end, as the code will be more efficient, unless we encounter memory problems, or you might want to save the entire lists at each iteration. In this manner, you will have all the necessary information in case your program crashes.</p> <pre><code>import time\n\ndef move(pos):\n    return float(pos)\n\ndef jog_and_measure(start=0, end=60, step=1, function=time.time):\n\n    position, measure = [], []\n    for pos in range(start, end+1, step):\n        position.append(move(pos))\n        measure.append(function())\n        print(position, measure)\n        time.sleep(wait_time=1)\n    # print(position, measure)\n    return 0\n\njog_and_measure(start=0, end=60, step=5, function=time.time)\n</code></pre> <p>Looks good. Here, we also added a move function and rewrote the class method as a function so that we can use it to explain how to save data without needing to connect to the linear stage.</p> <p>Now, let us also remove  time.time from the function definition, it can actually cause problems. And add parameters that we want to save, such as the step size, here called just step. And because we want to discuss more ways to save data, let us add a function to save data.</p> <pre><code>import time\n\ndef move(pos):\n    return float(pos)\n\ndef my_save_data(**kwargs):\n    print(kwargs)\n\ndef jog_and_measure(start=0, end=60, step=1, function=None):\n\n    if not function:\n        print(\"Need funcion\")\n        return 1\n\n    position, measure = [], []\n    for pos in range(start, end+1, step):\n        position.append(move(pos))\n        measure.append(function())\n        time.sleep(wait_time=1)\n        my_save_data(position=position, measure=measure, step=step)\n    return 0\n\njog_and_measure(start=0, end=60, step=5, function=time.time)\n</code></pre> <p>Here, we are actually printing a python dictionary, when we print kwargs. This keyword is a special symbol used for passing keyword arguments in Python. You can read more about it here.</p>"},{"location":"python/save_plot_data/#save-data","title":"Save data","text":"<p>As we saw, the easiest way to save data in python is to just print it. However, you might not like the formating. Here we show a way to improve this formatting:</p> <p><pre><code>def with_print_fancy(**kwargs):\n\n    print_as_list = []\n    for key, val in kwargs.items():\n        if not isinstance(val, list):\n            print(\"#\", \"%s: %s\" % (key, val))\n        else:\n            print_as_list.append(key)\n\n    print(\"#\", *print_as_list)\n    for row in zip(*(kwargs[i] for i in print_as_list)):\n        print(*row)\n</code></pre> You can add this function to your program and call it with:</p> <pre><code>with_print_fancy(position=position, measure=measure, step=step)\n</code></pre> <p>This will provide a nicer output, but it looks a bit complicated... It is easier to just add the parameters to the arguments of the function:</p> <pre><code>def with_print(parameters={}, **kwargs):\n\n    for key, val in parameters.items():\n        print(\"#\", \"%s: %s\" % (key, val))\n    print(\"#\", *kwargs.keys())\n    for row in zip(*kwargs.values()):\n        print(*row)\n</code></pre> <p>You can add this function to your program and call it with:</p> <pre><code>with_print(position=position, measure=measure, parameters={\"step\":step})\n</code></pre> <p>This will provide a nicer output. To write files you can simply redirect the output of print to a file:</p> <pre><code>def to_file(filename = \"out\", parameters={}, **kwargs):\n\n    filename = filename + \".txt\"\n    with open(filename, \"w\") as f:\n        for key, val in parameters.items():\n            print(\"#\", \"%s: %s\" % (key, val), file=f)\n        print(\"#\", *kwargs.keys(), file=f)\n        for row in zip(*kwargs.values()):\n            print(*row, file=f)\n</code></pre> <p>But honestly, this is a waste of time! There are better ways to write files. When programming you should always remember: \"Don't reinvent the wheel!\" and \"There is a good chance that someone already solved this small problem before\" (note: when programming you should always try to brake your problem into smaller parts).</p> <p>Better ways are usually found inside certain python packages. These also allow you to save the data in formats that you can then use with other programs, such as matlab or excell. Here we will recommend the modules numpy and json. </p> <pre><code>def with_json(filename = \"out\", **kwargs):\n    import json\n\n    filename = filename + \".json\"\n\n    with open(filename, \"w\") as f:\n        json.dump(kwargs, f)\n</code></pre> <p>See? This is short and easy!</p> <pre><code>def with_numpy(filename = \"out\", parameters={}, **kwargs):\n    import numpy as np\n\n    filename = filename + \".txt\"\n    header = \"\"\n    for key, val in parameters.items():\n        header += \"{}: {} \\n\".format(key, val)\n    header += \" \".join(kwargs.keys())\n\n    np.savetxt(filename, np.c_[ *kwargs.values() ], header=header)\n</code></pre> <p>Here is a complete example:</p> <p><pre><code>import time\nimport datetime\nimport save_data\n\ndef move(pos):\n    return float(pos)\n\ndef jog_and_measure(start=0, end=60, step=1, function=None):\n\n    if not function:\n        print(\"Need funcion\")\n        return 1\n\n    position, measure = [], []\n    filename = \"out_\"+str(datetime.datetime.now()).replace('.','_').replace(' ', '_').replace(':', '_')\n    for pos in range(start, end+1, step):\n        position.append(move(pos))\n        measure.append(function())\n\n        save_data.with_json(filename= filename, position=position, measure=measure, step=step)\n    return 0\n\njog_and_measure(start=0, end=60, step=5, function=time.time)\n</code></pre> Here, we use datetime to provide a timestamp that we include in filename. We do not create a new file, with new filename at every iteration of the loop though, we rewrite the json file at every iteration, which is less efficient but extremely useful if the computer crashes.</p>"},{"location":"python/save_plot_data/#plot-data","title":"Plot data","text":"<p>You will now need to load the data from the files and then plot the data. To load the data we still recommend numpy and json, but another powerful module to process data is pandas.</p> <p>For plotting, we will simply show you matplotlib, but there are others modules, such as plotly or seaborn.</p> <p><pre><code>import json\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\n\nfilenames = glob.glob(\"out*json\")\nprint(filenames)\n\nwith open(filenames[-1], \"r\") as f:\n    data = json.load(f)\n\nprint(data.keys())\ny = np.array(data[\"measure\"])\nfactor = y[0]\ny = y - factor\n\nplt.plot(data[\"position\"], y)\n# plt.show()\nplt.savefig(\"my_plot_{}.png\".format(data[\"step\"]))\n</code></pre> Which will result in:</p> <p></p>"},{"location":"python/save_plot_data/#exercise","title":"Exercise","text":"<p>Make the plot more beautiful, add legend and axis labels. </p> <pre><code>import json\nimport numpy as np\nimport glob\nimport matplotlib.pyplot as plt\n\nfilenames = glob.glob(\"out*json\")\nprint(filenames)\n\nwith open(filenames[-1], \"r\") as f:\n    data = json.load(f)\n\nprint(data.keys())\ny = np.array(data[\"measure\"])\nfactor = y[0]\ny = (y - factor)*1000\n\nplt.rcParams.update({'font.size': 15})\nfig, ax = plt.subplots(figsize=(8,8))\nax.plot(data[\"position\"], y,\n        linewidth=4, marker=\"o\", markersize=7,\n        label=\"Step = {} mm\".format(data[\"step\"]))\nax.legend()\nax.set_xlabel(\"Position (mm)\")\nax.set_ylabel(\"Power (mW)\")\nax.tick_params(axis='both', direction='in', top=True, right=True)\n\nplt.savefig(\"my_pretty_plot_{}.png\".format(data[\"step\"]))\n</code></pre> <p>There are more things you can change to make the plot more beautiful. You can change colors, font sizes, add other parameters or symbols... If you have Latex installed, you can easily use fonts and symbols from Latex.</p> <p>Here is the plot from the solution above:</p> <p></p>"}]}